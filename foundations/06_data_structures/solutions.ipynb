{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions: Graphs & Dependency Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1: Task Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Set, Optional\n",
    "from collections import defaultdict, deque\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Task:\n",
    "    name: str\n",
    "    depends_on: List[str]\n",
    "    duration: int\n",
    "\n",
    "\n",
    "class TaskScheduler:\n",
    "    \"\"\"Schedule tasks in dependency order.\"\"\"\n",
    "    \n",
    "    def __init__(self, tasks: List[Task]):\n",
    "        self.tasks = {task.name: task for task in tasks}\n",
    "        self.adjacency_list: Dict[str, List[str]] = defaultdict(list)\n",
    "        \n",
    "        self._build_graph()\n",
    "        self._validate()\n",
    "    \n",
    "    def _build_graph(self) -> None:\n",
    "        for task in self.tasks.values():\n",
    "            for dep in task.depends_on:\n",
    "                self.adjacency_list[dep].append(task.name)\n",
    "    \n",
    "    def _validate(self) -> None:\n",
    "        # Check missing dependencies\n",
    "        for task in self.tasks.values():\n",
    "            for dep in task.depends_on:\n",
    "                if dep not in self.tasks:\n",
    "                    raise ValueError(f\"Task '{task.name}' depends on '{dep}' which doesn't exist\")\n",
    "        \n",
    "        # Check cycles\n",
    "        visited = set()\n",
    "        rec_stack = set()\n",
    "        \n",
    "        def visit(name: str, path: List[str]) -> Optional[List[str]]:\n",
    "            if name in rec_stack:\n",
    "                cycle_start = path.index(name)\n",
    "                return path[cycle_start:] + [name]\n",
    "            if name in visited:\n",
    "                return None\n",
    "            \n",
    "            visited.add(name)\n",
    "            rec_stack.add(name)\n",
    "            path.append(name)\n",
    "            \n",
    "            for dependent in self.adjacency_list[name]:\n",
    "                cycle = visit(dependent, path[:])\n",
    "                if cycle:\n",
    "                    return cycle\n",
    "            \n",
    "            rec_stack.remove(name)\n",
    "            return None\n",
    "        \n",
    "        for task_name in self.tasks.keys():\n",
    "            if task_name not in visited:\n",
    "                cycle = visit(task_name, [])\n",
    "                if cycle:\n",
    "                    raise ValueError(f\"Circular dependency: {' -> '.join(cycle)}\")\n",
    "    \n",
    "    def get_execution_order(self) -> List[str]:\n",
    "        \"\"\"Topological sort.\"\"\"\n",
    "        in_degree = {name: len(task.depends_on) for name, task in self.tasks.items()}\n",
    "        queue = deque([name for name, degree in in_degree.items() if degree == 0])\n",
    "        result = []\n",
    "        \n",
    "        while queue:\n",
    "            task_name = queue.popleft()\n",
    "            result.append(task_name)\n",
    "            \n",
    "            for dependent in self.adjacency_list[task_name]:\n",
    "                in_degree[dependent] -= 1\n",
    "                if in_degree[dependent] == 0:\n",
    "                    queue.append(dependent)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_parallel_batches(self) -> List[List[str]]:\n",
    "        \"\"\"Execution layers.\"\"\"\n",
    "        in_degree = {name: len(task.depends_on) for name, task in self.tasks.items()}\n",
    "        batches = []\n",
    "        remaining = set(self.tasks.keys())\n",
    "        \n",
    "        while remaining:\n",
    "            current_batch = [name for name in remaining if in_degree[name] == 0]\n",
    "            batches.append(current_batch)\n",
    "            \n",
    "            for task_name in current_batch:\n",
    "                remaining.remove(task_name)\n",
    "                for dependent in self.adjacency_list[task_name]:\n",
    "                    if dependent in remaining:\n",
    "                        in_degree[dependent] -= 1\n",
    "        \n",
    "        return batches\n",
    "    \n",
    "    def estimate_completion_time(self) -> int:\n",
    "        \"\"\"Sum of max duration per batch.\"\"\"\n",
    "        batches = self.get_parallel_batches()\n",
    "        total_time = 0\n",
    "        \n",
    "        for batch in batches:\n",
    "            batch_duration = max(self.tasks[name].duration for name in batch)\n",
    "            total_time += batch_duration\n",
    "        \n",
    "        return total_time\n",
    "\n",
    "\n",
    "# Test\n",
    "tasks = [\n",
    "    Task(\"design\", [], 60),\n",
    "    Task(\"frontend\", [\"design\"], 120),\n",
    "    Task(\"backend\", [\"design\"], 180),\n",
    "    Task(\"database\", [\"design\"], 90),\n",
    "    Task(\"integration\", [\"frontend\", \"backend\", \"database\"], 60),\n",
    "    Task(\"testing\", [\"integration\"], 120),\n",
    "]\n",
    "\n",
    "scheduler = TaskScheduler(tasks)\n",
    "print(\"Execution order:\", scheduler.get_execution_order())\n",
    "print(\"\\nParallel batches:\")\n",
    "for i, batch in enumerate(scheduler.get_parallel_batches(), 1):\n",
    "    print(f\"  Batch {i}: {batch}\")\n",
    "print(f\"\\nEstimated completion time: {scheduler.estimate_completion_time()} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2: Detect All Cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_cycles(adjacency_list: Dict[str, List[str]]) -> List[List[str]]:\n",
    "    \"\"\"Find all cycles in a directed graph.\"\"\"\n",
    "    all_nodes = set(adjacency_list.keys())\n",
    "    for neighbors in adjacency_list.values():\n",
    "        all_nodes.update(neighbors)\n",
    "    \n",
    "    cycles = []\n",
    "    visited = set()\n",
    "    \n",
    "    def visit(node: str, rec_stack: Set[str], path: List[str]):\n",
    "        if node in rec_stack:\n",
    "            # Found a cycle\n",
    "            cycle_start = path.index(node)\n",
    "            cycle = path[cycle_start:] + [node]\n",
    "            # Normalize cycle (start from min node to avoid duplicates)\n",
    "            min_idx = cycle.index(min(cycle))\n",
    "            normalized = cycle[min_idx:-1] + cycle[:min_idx] + [cycle[min_idx]]\n",
    "            if normalized not in cycles:\n",
    "                cycles.append(normalized)\n",
    "            return\n",
    "        \n",
    "        if node in visited:\n",
    "            return\n",
    "        \n",
    "        visited.add(node)\n",
    "        rec_stack.add(node)\n",
    "        path.append(node)\n",
    "        \n",
    "        for neighbor in adjacency_list.get(node, []):\n",
    "            visit(neighbor, rec_stack, path[:])\n",
    "        \n",
    "        rec_stack.remove(node)\n",
    "    \n",
    "    for node in all_nodes:\n",
    "        visit(node, set(), [])\n",
    "    \n",
    "    return cycles\n",
    "\n",
    "\n",
    "# Test\n",
    "graph = {\n",
    "    \"A\": [\"B\"],\n",
    "    \"B\": [\"C\"],\n",
    "    \"C\": [\"A\"],\n",
    "    \"D\": [\"E\"],\n",
    "    \"E\": [\"D\"],\n",
    "}\n",
    "\n",
    "cycles = find_all_cycles(graph)\n",
    "print(\"Cycles found:\")\n",
    "for cycle in cycles:\n",
    "    print(f\"  {' -> '.join(cycle)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 3: Course Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def course_order(num_courses: int, prerequisites: List[tuple[int, int]]) -> List[int] | None:\n",
    "    \"\"\"Find valid course order using topological sort.\"\"\"\n",
    "    # Build adjacency list\n",
    "    adjacency_list = defaultdict(list)\n",
    "    in_degree = {i: 0 for i in range(num_courses)}\n",
    "    \n",
    "    for course, prereq in prerequisites:\n",
    "        adjacency_list[prereq].append(course)\n",
    "        in_degree[course] += 1\n",
    "    \n",
    "    # Kahn's algorithm\n",
    "    queue = deque([course for course, degree in in_degree.items() if degree == 0])\n",
    "    result = []\n",
    "    \n",
    "    while queue:\n",
    "        course = queue.popleft()\n",
    "        result.append(course)\n",
    "        \n",
    "        for dependent in adjacency_list[course]:\n",
    "            in_degree[dependent] -= 1\n",
    "            if in_degree[dependent] == 0:\n",
    "                queue.append(dependent)\n",
    "    \n",
    "    # Check if all courses processed\n",
    "    if len(result) != num_courses:\n",
    "        return None  # Cycle detected\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Test 1: Valid\n",
    "result = course_order(4, [(1, 0), (2, 0), (3, 1), (3, 2)])\n",
    "print(\"Course order:\", result)\n",
    "\n",
    "# Test 2: Cycle\n",
    "result = course_order(2, [(0, 1), (1, 0)])\n",
    "print(\"Course order with cycle:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 4: Transitive Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dependencies(\n",
    "    package: str,\n",
    "    dependencies: Dict[str, List[str]]\n",
    ") -> Set[str]:\n",
    "    \"\"\"BFS to collect all transitive dependencies.\"\"\"\n",
    "    all_deps = set()\n",
    "    queue = deque([package])\n",
    "    visited = {package}\n",
    "    \n",
    "    while queue:\n",
    "        current = queue.popleft()\n",
    "        \n",
    "        for dep in dependencies.get(current, []):\n",
    "            all_deps.add(dep)\n",
    "            if dep not in visited:\n",
    "                visited.add(dep)\n",
    "                queue.append(dep)\n",
    "    \n",
    "    return all_deps\n",
    "\n",
    "\n",
    "# Test\n",
    "deps = {\n",
    "    \"A\": [\"B\", \"C\"],\n",
    "    \"B\": [\"D\"],\n",
    "    \"C\": [\"D\", \"E\"],\n",
    "    \"D\": [],\n",
    "    \"E\": [\"F\"],\n",
    "    \"F\": [],\n",
    "}\n",
    "\n",
    "all_deps = get_all_dependencies(\"A\", deps)\n",
    "print(\"All dependencies of A:\", sorted(all_deps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 5: Build Order with Circular Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_order(\n",
    "    projects: Dict[str, List[str]]\n",
    ") -> tuple[List[str] | None, List[str] | None]:\n",
    "    \"\"\"Determine build order or find circular dependency.\"\"\"\n",
    "    # Build adjacency list\n",
    "    adjacency_list = defaultdict(list)\n",
    "    all_projects = set(projects.keys())\n",
    "    in_degree = {proj: 0 for proj in all_projects}\n",
    "    \n",
    "    for proj, deps in projects.items():\n",
    "        for dep in deps:\n",
    "            adjacency_list[dep].append(proj)\n",
    "            in_degree[proj] += 1\n",
    "            all_projects.add(dep)\n",
    "    \n",
    "    # Add projects with no dependencies\n",
    "    for proj in all_projects:\n",
    "        if proj not in in_degree:\n",
    "            in_degree[proj] = 0\n",
    "    \n",
    "    # Try topological sort\n",
    "    queue = deque([proj for proj, degree in in_degree.items() if degree == 0])\n",
    "    result = []\n",
    "    \n",
    "    while queue:\n",
    "        proj = queue.popleft()\n",
    "        result.append(proj)\n",
    "        \n",
    "        for dependent in adjacency_list[proj]:\n",
    "            in_degree[dependent] -= 1\n",
    "            if in_degree[dependent] == 0:\n",
    "                queue.append(dependent)\n",
    "    \n",
    "    # Check if successful\n",
    "    if len(result) == len(all_projects):\n",
    "        return result, None\n",
    "    \n",
    "    # Find cycle using DFS\n",
    "    visited = set()\n",
    "    rec_stack = set()\n",
    "    \n",
    "    def find_cycle(proj: str, path: List[str]) -> List[str] | None:\n",
    "        if proj in rec_stack:\n",
    "            cycle_start = path.index(proj)\n",
    "            return path[cycle_start:] + [proj]\n",
    "        if proj in visited:\n",
    "            return None\n",
    "        \n",
    "        visited.add(proj)\n",
    "        rec_stack.add(proj)\n",
    "        path.append(proj)\n",
    "        \n",
    "        for dependent in adjacency_list[proj]:\n",
    "            cycle = find_cycle(dependent, path[:])\n",
    "            if cycle:\n",
    "                return cycle\n",
    "        \n",
    "        rec_stack.remove(proj)\n",
    "        return None\n",
    "    \n",
    "    for proj in all_projects:\n",
    "        if proj not in visited:\n",
    "            cycle = find_cycle(proj, [])\n",
    "            if cycle:\n",
    "                return None, cycle\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "\n",
    "# Test 1: Valid\n",
    "projects = {\n",
    "    \"app\": [\"utils\", \"data\"],\n",
    "    \"utils\": [],\n",
    "    \"data\": [\"utils\"],\n",
    "    \"api\": [\"data\"],\n",
    "}\n",
    "order, cycle = build_order(projects)\n",
    "print(\"Build order:\", order)\n",
    "print(\"Cycle:\", cycle)\n",
    "\n",
    "# Test 2: Cycle\n",
    "projects_cyclic = {\n",
    "    \"app\": [\"api\"],\n",
    "    \"api\": [\"data\"],\n",
    "    \"data\": [\"app\"],\n",
    "}\n",
    "order, cycle = build_order(projects_cyclic)\n",
    "print(\"\\nBuild order:\", order)\n",
    "print(\"Cycle:\", cycle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Solution: Minimum Build Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_build_time(\n",
    "    tasks: Dict[str, tuple[List[str], int]]\n",
    ") -> tuple[int, Dict[str, int]]:\n",
    "    \"\"\"Calculate minimum build time with parallel execution.\"\"\"\n",
    "    # Build adjacency list and calculate in-degrees\n",
    "    adjacency_list = defaultdict(list)\n",
    "    in_degree = {name: 0 for name in tasks.keys()}\n",
    "    \n",
    "    for task, (deps, _) in tasks.items():\n",
    "        in_degree[task] = len(deps)\n",
    "        for dep in deps:\n",
    "            adjacency_list[dep].append(task)\n",
    "    \n",
    "    # Topological sort with finish time calculation\n",
    "    queue = deque([task for task, degree in in_degree.items() if degree == 0])\n",
    "    finish_times = {}\n",
    "    \n",
    "    while queue:\n",
    "        task = queue.popleft()\n",
    "        deps, duration = tasks[task]\n",
    "        \n",
    "        # Start time = max finish time of dependencies\n",
    "        start_time = max((finish_times[dep] for dep in deps), default=0)\n",
    "        finish_times[task] = start_time + duration\n",
    "        \n",
    "        # Process dependents\n",
    "        for dependent in adjacency_list[task]:\n",
    "            in_degree[dependent] -= 1\n",
    "            if in_degree[dependent] == 0:\n",
    "                queue.append(dependent)\n",
    "    \n",
    "    total_time = max(finish_times.values())\n",
    "    return total_time, finish_times\n",
    "\n",
    "\n",
    "# Test\n",
    "tasks = {\n",
    "    \"A\": ([], 3),\n",
    "    \"B\": ([\"A\"], 2),\n",
    "    \"C\": ([\"A\"], 4),\n",
    "    \"D\": ([\"B\", \"C\"], 1),\n",
    "}\n",
    "\n",
    "total, finish_times = minimum_build_time(tasks)\n",
    "print(\"Minimum build time:\", total)\n",
    "print(\"Finish times:\", finish_times)\n",
    "\n",
    "# Verify\n",
    "assert finish_times[\"A\"] == 3, \"A finishes at 3\"\n",
    "assert finish_times[\"B\"] == 5, \"B starts at 3, finishes at 5\"\n",
    "assert finish_times[\"C\"] == 7, \"C starts at 3, finishes at 7\"\n",
    "assert finish_times[\"D\"] == 8, \"D starts at 7 (max of B=5, C=7), finishes at 8\"\n",
    "assert total == 8\n",
    "print(\"\\nâœ“ All assertions passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Key Patterns\n",
    "\n",
    "1. **Topological Sort = Kahn's Algorithm**\n",
    "   - Queue nodes with in-degree 0\n",
    "   - Process, reduce neighbors' in-degree\n",
    "   - If all processed â†’ valid, else cycle\n",
    "\n",
    "2. **Cycle Detection = DFS with Recursion Stack**\n",
    "   - `visited`: Fully processed nodes\n",
    "   - `rec_stack`: Current path\n",
    "   - Back edge (node in `rec_stack`) = cycle\n",
    "\n",
    "3. **Execution Layers = Iterative In-Degree**\n",
    "   - Each layer = nodes with in-degree 0\n",
    "   - Remove layer, recalculate in-degrees\n",
    "   - Repeat until empty\n",
    "\n",
    "4. **Transitive Closure = BFS/DFS**\n",
    "   - Start from node\n",
    "   - Traverse all reachable nodes\n",
    "   - Collect visited set\n",
    "\n",
    "5. **Critical Path = Topological + Max Accumulation**\n",
    "   - Process nodes in topological order\n",
    "   - Finish time = max(dep finish times) + duration\n",
    "   - Total = max finish time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
