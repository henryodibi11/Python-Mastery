{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context API - Solutions\n",
    "\n",
    "Complete implementations for all exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'c:\\Users\\hodibi\\OneDrive - Ingredion\\Desktop\\Repos\\Odibi')\n",
    "\n",
    "from odibi.context import Context, PandasContext\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, List, Callable, Set\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1: Snapshot Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnapshotContext(PandasContext):\n",
    "    \"\"\"Context with named snapshot capability.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._snapshots: Dict[str, Dict[str, pd.DataFrame]] = {}\n",
    "    \n",
    "    def snapshot(self, name: str) -> None:\n",
    "        \"\"\"Save current state with name.\"\"\"\n",
    "        # Deep copy to avoid reference issues\n",
    "        self._snapshots[name] = {k: v.copy() for k, v in self._data.items()}\n",
    "    \n",
    "    def restore(self, name: str) -> None:\n",
    "        \"\"\"Restore to named snapshot.\"\"\"\n",
    "        if name not in self._snapshots:\n",
    "            available = \", \".join(self._snapshots.keys()) if self._snapshots else \"none\"\n",
    "            raise KeyError(f\"Snapshot '{name}' not found. Available: {available}\")\n",
    "        \n",
    "        # Restore by copying snapshot data\n",
    "        self._data = {k: v.copy() for k, v in self._snapshots[name].items()}\n",
    "    \n",
    "    def list_snapshots(self) -> List[str]:\n",
    "        \"\"\"List available snapshots.\"\"\"\n",
    "        return list(self._snapshots.keys())\n",
    "\n",
    "# Test\n",
    "ctx = SnapshotContext()\n",
    "ctx.register('a', pd.DataFrame({'x': [1, 2]}))\n",
    "ctx.snapshot('initial')\n",
    "\n",
    "ctx.register('b', pd.DataFrame({'y': [3, 4]}))\n",
    "ctx.snapshot('with_b')\n",
    "\n",
    "ctx.register('c', pd.DataFrame({'z': [5, 6]}))\n",
    "print(\"Current:\", ctx.list_names())\n",
    "print(\"Snapshots:\", ctx.list_snapshots())\n",
    "\n",
    "ctx.restore('initial')\n",
    "print(\"After restore:\", ctx.list_names())\n",
    "assert ctx.list_names() == ['a']\n",
    "print(\"âœ… Solution 1 works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "- Use `copy()` to avoid shared references\n",
    "- Store snapshots in a dict for named access\n",
    "- Provide helpful error messages with available snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2: Serializable Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SerializableContext(PandasContext):\n",
    "    \"\"\"Context that can be saved/loaded from disk.\"\"\"\n",
    "    \n",
    "    def save(self, path: str) -> None:\n",
    "        \"\"\"Save context to file.\"\"\"\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self._data, f)\n",
    "    \n",
    "    def load(self, path: str) -> None:\n",
    "        \"\"\"Load context from file.\"\"\"\n",
    "        if not Path(path).exists():\n",
    "            raise FileNotFoundError(f\"Context file not found: {path}\")\n",
    "        \n",
    "        with open(path, 'rb') as f:\n",
    "            self._data = pickle.load(f)\n",
    "\n",
    "# Test\n",
    "ctx = SerializableContext()\n",
    "ctx.register('data', pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]}))\n",
    "\n",
    "ctx.save('test_context.pkl')\n",
    "print(\"Saved:\", ctx.list_names())\n",
    "\n",
    "ctx2 = SerializableContext()\n",
    "ctx2.load('test_context.pkl')\n",
    "print(\"Loaded:\", ctx2.list_names())\n",
    "assert ctx2.get('data').equals(ctx.get('data'))\n",
    "\n",
    "Path('test_context.pkl').unlink()\n",
    "print(\"âœ… Solution 2 works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "- Pickle handles Pandas DataFrames well\n",
    "- Check file existence before loading\n",
    "- Remember to use binary mode ('wb'/'rb')\n",
    "\n",
    "### Alternative: Parquet for production\n",
    "For real systems, consider saving each DataFrame as Parquet + metadata JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 3: Observable Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservableContext(PandasContext):\n",
    "    \"\"\"Context that notifies observers of changes.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._observers: Set[Callable[[str, str | None], None]] = set()\n",
    "    \n",
    "    def subscribe(self, callback: Callable[[str, str | None], None]) -> None:\n",
    "        \"\"\"Add observer.\"\"\"\n",
    "        self._observers.add(callback)\n",
    "    \n",
    "    def unsubscribe(self, callback: Callable[[str, str | None], None]) -> None:\n",
    "        \"\"\"Remove observer.\"\"\"\n",
    "        self._observers.discard(callback)\n",
    "    \n",
    "    def _notify(self, event: str, name: str | None = None) -> None:\n",
    "        \"\"\"Notify all observers.\"\"\"\n",
    "        for observer in self._observers:\n",
    "            observer(event, name)\n",
    "    \n",
    "    def register(self, name: str, df: pd.DataFrame) -> None:\n",
    "        \"\"\"Register and notify.\"\"\"\n",
    "        super().register(name, df)\n",
    "        self._notify('register', name)\n",
    "    \n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear and notify.\"\"\"\n",
    "        super().clear()\n",
    "        self._notify('clear', None)\n",
    "\n",
    "# Test\n",
    "events = []\n",
    "\n",
    "def logger(event: str, name: str | None):\n",
    "    events.append((event, name))\n",
    "    print(f\"ðŸ“¢ {event}: {name}\")\n",
    "\n",
    "ctx = ObservableContext()\n",
    "ctx.subscribe(logger)\n",
    "\n",
    "ctx.register('df1', pd.DataFrame({'x': [1]}))\n",
    "ctx.register('df2', pd.DataFrame({'y': [2]}))\n",
    "ctx.clear()\n",
    "\n",
    "assert events == [('register', 'df1'), ('register', 'df2'), ('clear', None)]\n",
    "print(\"âœ… Solution 3 works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "- Use `set()` to avoid duplicate observers\n",
    "- Call `super()` methods first, then notify\n",
    "- Observer pattern enables logging, metrics, debugging\n",
    "\n",
    "### Use Cases\n",
    "- Audit logging: Track all data registrations\n",
    "- Metrics: Count context operations\n",
    "- Debugging: Print context changes in dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 4: Validating Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ValidatingContext(PandasContext):\n",
    "    \"\"\"Context with schema validation.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._schemas: Dict[str, Dict[str, type]] = {}\n",
    "    \n",
    "    def set_schema(self, name: str, schema: Dict[str, type]) -> None:\n",
    "        \"\"\"Define expected schema for a DataFrame.\"\"\"\n",
    "        self._schemas[name] = schema\n",
    "    \n",
    "    def _validate_schema(self, name: str, df: pd.DataFrame) -> None:\n",
    "        \"\"\"Check if DataFrame matches schema.\"\"\"\n",
    "        if name not in self._schemas:\n",
    "            return  # No schema defined, skip validation\n",
    "        \n",
    "        schema = self._schemas[name]\n",
    "        \n",
    "        # Check for missing columns\n",
    "        missing = set(schema.keys()) - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing columns: {missing}\")\n",
    "        \n",
    "        # Check types\n",
    "        for col, expected_type in schema.items():\n",
    "            actual_type = df[col].dtype\n",
    "            if actual_type != expected_type:\n",
    "                raise ValueError(\n",
    "                    f\"Column '{col}' has type {actual_type}, expected {expected_type}\"\n",
    "                )\n",
    "    \n",
    "    def register(self, name: str, df: pd.DataFrame) -> None:\n",
    "        \"\"\"Register with validation.\"\"\"\n",
    "        self._validate_schema(name, df)\n",
    "        super().register(name, df)\n",
    "\n",
    "# Test\n",
    "ctx = ValidatingContext()\n",
    "ctx.set_schema('customers', {\n",
    "    'customer_id': np.int64,\n",
    "    'name': object\n",
    "})\n",
    "\n",
    "# Valid DataFrame\n",
    "valid_df = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3],\n",
    "    'name': ['Alice', 'Bob', 'Carol']\n",
    "})\n",
    "ctx.register('customers', valid_df)\n",
    "print(\"âœ… Valid DataFrame registered\")\n",
    "\n",
    "# Invalid: missing column\n",
    "try:\n",
    "    ctx.register('customers', pd.DataFrame({'customer_id': [1]}))\n",
    "    assert False, \"Should have raised ValueError\"\n",
    "except ValueError as e:\n",
    "    print(f\"âŒ Caught: {e}\")\n",
    "\n",
    "# Invalid: wrong type\n",
    "try:\n",
    "    invalid_df = pd.DataFrame({\n",
    "        'customer_id': ['a', 'b'],\n",
    "        'name': ['Alice', 'Bob']\n",
    "    })\n",
    "    ctx.register('customers', invalid_df)\n",
    "    assert False, \"Should have raised ValueError\"\n",
    "except ValueError as e:\n",
    "    print(f\"âŒ Caught: {e}\")\n",
    "\n",
    "print(\"âœ… Solution 4 works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "- Validate before calling `super().register()`\n",
    "- Check both missing columns and type mismatches\n",
    "- Skip validation if no schema defined\n",
    "\n",
    "### Production Enhancements\n",
    "- Use `pandera` or `great_expectations` for richer validation\n",
    "- Support nullable columns\n",
    "- Validate ranges, patterns, uniqueness constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: SuperContext\n",
    "\n",
    "Combines LRU caching, snapshots, and observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class SuperContext(Context):\n",
    "    \"\"\"Context with LRU caching, snapshots, and observers.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size: int = 10):\n",
    "        self.max_size = max_size\n",
    "        self._data: OrderedDict[str, pd.DataFrame] = OrderedDict()\n",
    "        self._snapshots: Dict[str, Dict[str, pd.DataFrame]] = {}\n",
    "        self._observers: Set[Callable[[str, str | None], None]] = set()\n",
    "        self._eviction_count = 0\n",
    "    \n",
    "    # Observer methods\n",
    "    def subscribe(self, callback: Callable[[str, str | None], None]) -> None:\n",
    "        self._observers.add(callback)\n",
    "    \n",
    "    def _notify(self, event: str, name: str | None = None) -> None:\n",
    "        for observer in self._observers:\n",
    "            observer(event, name)\n",
    "    \n",
    "    # Snapshot methods\n",
    "    def snapshot(self, name: str) -> None:\n",
    "        # Note: Don't snapshot observers (implementation choice)\n",
    "        self._snapshots[name] = {k: v.copy() for k, v in self._data.items()}\n",
    "        self._notify('snapshot', name)\n",
    "    \n",
    "    def restore(self, name: str) -> None:\n",
    "        if name not in self._snapshots:\n",
    "            raise KeyError(f\"Snapshot '{name}' not found\")\n",
    "        self._data = OrderedDict({k: v.copy() for k, v in self._snapshots[name].items()})\n",
    "        self._notify('restore', name)\n",
    "    \n",
    "    # Context ABC methods (with LRU)\n",
    "    def register(self, name: str, df: pd.DataFrame) -> None:\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            raise TypeError(f\"Expected pandas.DataFrame, got {type(df)}\")\n",
    "        \n",
    "        if name in self._data:\n",
    "            del self._data[name]\n",
    "        \n",
    "        # LRU eviction\n",
    "        if len(self._data) >= self.max_size:\n",
    "            evicted_name, _ = self._data.popitem(last=False)\n",
    "            self._eviction_count += 1\n",
    "            self._notify('evict', evicted_name)\n",
    "        \n",
    "        self._data[name] = df\n",
    "        self._notify('register', name)\n",
    "    \n",
    "    def get(self, name: str) -> pd.DataFrame:\n",
    "        if name not in self._data:\n",
    "            raise KeyError(f\"DataFrame '{name}' not found\")\n",
    "        self._data.move_to_end(name)\n",
    "        self._notify('get', name)\n",
    "        return self._data[name]\n",
    "    \n",
    "    def has(self, name: str) -> bool:\n",
    "        return name in self._data\n",
    "    \n",
    "    def list_names(self) -> List[str]:\n",
    "        return list(self._data.keys())\n",
    "    \n",
    "    def clear(self) -> None:\n",
    "        self._data.clear()\n",
    "        self._eviction_count = 0\n",
    "        self._notify('clear', None)\n",
    "\n",
    "# Test combined features\n",
    "events = []\n",
    "ctx = SuperContext(max_size=2)\n",
    "ctx.subscribe(lambda e, n: events.append((e, n)))\n",
    "\n",
    "ctx.register('a', pd.DataFrame({'x': [1]}))\n",
    "ctx.snapshot('s1')\n",
    "ctx.register('b', pd.DataFrame({'x': [2]}))\n",
    "ctx.register('c', pd.DataFrame({'x': [3]}))  # Evicts 'a'\n",
    "\n",
    "print(\"Events:\", events)\n",
    "print(\"Current:\", ctx.list_names())\n",
    "\n",
    "ctx.restore('s1')\n",
    "print(\"After restore:\", ctx.list_names())\n",
    "print(\"âœ… SuperContext works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design Decisions\n",
    "1. **Snapshots don't include observers** - observers are runtime concerns, snapshots are data\n",
    "2. **Evictions trigger events** - helps debug cache misses\n",
    "3. **OrderedDict for LRU** - simpler than separate tracking\n",
    "\n",
    "### Trade-offs\n",
    "- More features = more complexity\n",
    "- Consider composition over inheritance for production\n",
    "- Document feature interactions clearly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
