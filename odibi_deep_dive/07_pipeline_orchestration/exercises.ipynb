{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Orchestration Exercises\n",
    "\n",
    "Practice orchestrating complete pipeline execution flows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Build a Simple Pipeline Executor\n",
    "\n",
    "Create a simplified Pipeline class that:\n",
    "1. Takes a list of node configs\n",
    "2. Determines execution order\n",
    "3. Executes nodes sequentially\n",
    "4. Tracks completed/failed/skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Callable\n",
    "\n",
    "@dataclass\n",
    "class SimpleNodeConfig:\n",
    "    name: str\n",
    "    depends_on: List[str] = field(default_factory=list)\n",
    "    # Function that executes the node (returns True for success, False for failure)\n",
    "    execute_fn: Callable[[], bool] = None\n",
    "\n",
    "@dataclass\n",
    "class SimplePipelineResults:\n",
    "    completed: List[str] = field(default_factory=list)\n",
    "    failed: List[str] = field(default_factory=list)\n",
    "    skipped: List[str] = field(default_factory=list)\n",
    "\n",
    "class SimplePipeline:\n",
    "    def __init__(self, nodes: List[SimpleNodeConfig]):\n",
    "        # TODO: Store nodes\n",
    "        pass\n",
    "    \n",
    "    def _topological_sort(self) -> List[str]:\n",
    "        \"\"\"Return execution order using topological sort.\"\"\"\n",
    "        # TODO: Implement topological sort\n",
    "        # Hint: Use the algorithm from Module 5\n",
    "        pass\n",
    "    \n",
    "    def run(self) -> SimplePipelineResults:\n",
    "        \"\"\"Execute pipeline and return results.\"\"\"\n",
    "        results = SimplePipelineResults()\n",
    "        \n",
    "        # TODO: Get execution order\n",
    "        # TODO: For each node:\n",
    "        #   - Check if dependencies failed\n",
    "        #   - Skip if yes\n",
    "        #   - Execute and track result\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test your implementation\n",
    "nodes = [\n",
    "    SimpleNodeConfig(\"A\", [], lambda: True),\n",
    "    SimpleNodeConfig(\"B\", [], lambda: False),  # This fails\n",
    "    SimpleNodeConfig(\"C\", [\"A\"], lambda: True),\n",
    "    SimpleNodeConfig(\"D\", [\"B\"], lambda: True),  # Should be skipped\n",
    "    SimpleNodeConfig(\"E\", [\"C\", \"D\"], lambda: True),  # Should be skipped\n",
    "]\n",
    "\n",
    "pipeline = SimplePipeline(nodes)\n",
    "results = pipeline.run()\n",
    "\n",
    "print(f\"Completed: {results.completed}\")  # Should be ['A', 'C']\n",
    "print(f\"Failed: {results.failed}\")  # Should be ['B']\n",
    "print(f\"Skipped: {results.skipped}\")  # Should be ['D', 'E']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Implement Layer Detection\n",
    "\n",
    "Group nodes into execution layers based on dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_execution_layers(nodes: Dict[str, List[str]]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Group nodes into layers for parallel execution.\n",
    "    \n",
    "    Args:\n",
    "        nodes: Dict mapping node name to list of dependencies\n",
    "    \n",
    "    Returns:\n",
    "        List of layers, where each layer is a list of node names\n",
    "    \n",
    "    Example:\n",
    "        Input: {'A': [], 'B': [], 'C': ['A'], 'D': ['A', 'B'], 'E': ['C', 'D']}\n",
    "        Output: [['A', 'B'], ['C', 'D'], ['E']]\n",
    "    \"\"\"\n",
    "    # TODO: Implement layer detection\n",
    "    # Hint: Layer 0 has no dependencies\n",
    "    # Layer 1 depends only on Layer 0\n",
    "    # Layer N depends only on Layers 0..N-1\n",
    "    pass\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        'nodes': {'A': [], 'B': [], 'C': ['A'], 'D': ['A', 'B'], 'E': ['C', 'D']},\n",
    "        'expected': [['A', 'B'], ['C', 'D'], ['E']]\n",
    "    },\n",
    "    {\n",
    "        'nodes': {'A': [], 'B': ['A'], 'C': ['B'], 'D': ['C']},\n",
    "        'expected': [['A'], ['B'], ['C'], ['D']]\n",
    "    },\n",
    "    {\n",
    "        'nodes': {'A': [], 'B': [], 'C': [], 'D': ['A', 'B', 'C']},\n",
    "        'expected': [['A', 'B', 'C'], ['D']]\n",
    "    },\n",
    "]\n",
    "\n",
    "for i, test in enumerate(test_cases, 1):\n",
    "    result = get_execution_layers(test['nodes'])\n",
    "    # Sort for comparison (order within layer doesn't matter)\n",
    "    result_sorted = [sorted(layer) for layer in result]\n",
    "    expected_sorted = [sorted(layer) for layer in test['expected']]\n",
    "    \n",
    "    if result_sorted == expected_sorted:\n",
    "        print(f\"✅ Test {i} passed\")\n",
    "    else:\n",
    "        print(f\"❌ Test {i} failed\")\n",
    "        print(f\"   Expected: {expected_sorted}\")\n",
    "        print(f\"   Got: {result_sorted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Build PipelineResults Aggregator\n",
    "\n",
    "Aggregate results from multiple pipeline runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PipelineRun:\n",
    "    pipeline_name: str\n",
    "    completed: List[str]\n",
    "    failed: List[str]\n",
    "    skipped: List[str]\n",
    "    duration: float\n",
    "\n",
    "@dataclass\n",
    "class AggregatedResults:\n",
    "    total_pipelines: int\n",
    "    successful_pipelines: int\n",
    "    failed_pipelines: int\n",
    "    total_nodes: int\n",
    "    total_completed: int\n",
    "    total_failed: int\n",
    "    total_skipped: int\n",
    "    total_duration: float\n",
    "    \n",
    "    def success_rate(self) -> float:\n",
    "        \"\"\"Calculate node success rate.\"\"\"\n",
    "        if self.total_nodes == 0:\n",
    "            return 0.0\n",
    "        return (self.total_completed / self.total_nodes) * 100\n",
    "\n",
    "def aggregate_pipeline_results(runs: List[PipelineRun]) -> AggregatedResults:\n",
    "    \"\"\"\n",
    "    Aggregate results from multiple pipeline runs.\n",
    "    \n",
    "    A pipeline is considered successful if it has no failed nodes.\n",
    "    \"\"\"\n",
    "    # TODO: Calculate aggregated statistics\n",
    "    pass\n",
    "\n",
    "# Test data\n",
    "runs = [\n",
    "    PipelineRun(\n",
    "        pipeline_name=\"bronze_to_silver\",\n",
    "        completed=[\"A\", \"B\", \"C\"],\n",
    "        failed=[],\n",
    "        skipped=[],\n",
    "        duration=10.5\n",
    "    ),\n",
    "    PipelineRun(\n",
    "        pipeline_name=\"silver_to_gold\",\n",
    "        completed=[\"D\", \"E\"],\n",
    "        failed=[\"F\"],\n",
    "        skipped=[\"G\", \"H\"],\n",
    "        duration=5.2\n",
    "    ),\n",
    "    PipelineRun(\n",
    "        pipeline_name=\"gold_analytics\",\n",
    "        completed=[\"I\", \"J\", \"K\", \"L\"],\n",
    "        failed=[],\n",
    "        skipped=[],\n",
    "        duration=8.3\n",
    "    ),\n",
    "]\n",
    "\n",
    "agg = aggregate_pipeline_results(runs)\n",
    "\n",
    "print(f\"Total Pipelines: {agg.total_pipelines}\")  # Should be 3\n",
    "print(f\"Successful: {agg.successful_pipelines}\")  # Should be 2\n",
    "print(f\"Failed: {agg.failed_pipelines}\")  # Should be 1\n",
    "print(f\"Total Nodes: {agg.total_nodes}\")  # Should be 12\n",
    "print(f\"Completed: {agg.total_completed}\")  # Should be 9\n",
    "print(f\"Failed: {agg.total_failed}\")  # Should be 1\n",
    "print(f\"Skipped: {agg.total_skipped}\")  # Should be 2\n",
    "print(f\"Total Duration: {agg.total_duration:.1f}s\")  # Should be 24.0\n",
    "print(f\"Success Rate: {agg.success_rate():.1f}%\")  # Should be 75.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Pipeline Validation\n",
    "\n",
    "Implement comprehensive pipeline validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ValidationResult:\n",
    "    valid: bool\n",
    "    errors: List[str] = field(default_factory=list)\n",
    "    warnings: List[str] = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class NodeDef:\n",
    "    name: str\n",
    "    depends_on: List[str]\n",
    "    connection: str\n",
    "\n",
    "def validate_pipeline(\n",
    "    nodes: List[NodeDef],\n",
    "    available_connections: List[str]\n",
    ") -> ValidationResult:\n",
    "    \"\"\"\n",
    "    Validate pipeline configuration.\n",
    "    \n",
    "    Checks:\n",
    "    1. No circular dependencies\n",
    "    2. All dependencies exist\n",
    "    3. Connections are available (warning if missing)\n",
    "    4. No duplicate node names\n",
    "    \"\"\"\n",
    "    result = ValidationResult(valid=True)\n",
    "    \n",
    "    # TODO: Implement validation checks\n",
    "    # Set result.valid = False if any errors found\n",
    "    # Add errors to result.errors\n",
    "    # Add warnings to result.warnings\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test cases\n",
    "test_valid = [\n",
    "    NodeDef(\"A\", [], \"local\"),\n",
    "    NodeDef(\"B\", [\"A\"], \"local\"),\n",
    "    NodeDef(\"C\", [\"B\"], \"azure\"),\n",
    "]\n",
    "\n",
    "test_circular = [\n",
    "    NodeDef(\"A\", [\"B\"], \"local\"),\n",
    "    NodeDef(\"B\", [\"C\"], \"local\"),\n",
    "    NodeDef(\"C\", [\"A\"], \"local\"),  # Circular!\n",
    "]\n",
    "\n",
    "test_missing_dep = [\n",
    "    NodeDef(\"A\", [], \"local\"),\n",
    "    NodeDef(\"B\", [\"X\"], \"local\"),  # X doesn't exist!\n",
    "]\n",
    "\n",
    "test_duplicate = [\n",
    "    NodeDef(\"A\", [], \"local\"),\n",
    "    NodeDef(\"A\", [], \"local\"),  # Duplicate!\n",
    "]\n",
    "\n",
    "connections = [\"local\", \"azure\"]\n",
    "\n",
    "print(\"Test 1 - Valid pipeline:\")\n",
    "result = validate_pipeline(test_valid, connections)\n",
    "print(f\"  Valid: {result.valid}\")\n",
    "print(f\"  Errors: {result.errors}\")\n",
    "\n",
    "print(\"\\nTest 2 - Circular dependency:\")\n",
    "result = validate_pipeline(test_circular, connections)\n",
    "print(f\"  Valid: {result.valid}\")\n",
    "print(f\"  Errors: {result.errors}\")\n",
    "\n",
    "print(\"\\nTest 3 - Missing dependency:\")\n",
    "result = validate_pipeline(test_missing_dep, connections)\n",
    "print(f\"  Valid: {result.valid}\")\n",
    "print(f\"  Errors: {result.errors}\")\n",
    "\n",
    "print(\"\\nTest 4 - Duplicate nodes:\")\n",
    "result = validate_pipeline(test_duplicate, connections)\n",
    "print(f\"  Valid: {result.valid}\")\n",
    "print(f\"  Errors: {result.errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Pipeline Execution Simulator\n",
    "\n",
    "Create a complete pipeline execution simulator with timing and random failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "@dataclass\n",
    "class SimulatedNode:\n",
    "    name: str\n",
    "    depends_on: List[str]\n",
    "    duration: float  # Seconds\n",
    "    failure_rate: float  # 0.0 to 1.0\n",
    "\n",
    "@dataclass\n",
    "class ExecutionResults:\n",
    "    pipeline_name: str\n",
    "    completed: List[str] = field(default_factory=list)\n",
    "    failed: List[str] = field(default_factory=list)\n",
    "    skipped: List[str] = field(default_factory=list)\n",
    "    node_durations: Dict[str, float] = field(default_factory=dict)\n",
    "    start_time: str = \"\"\n",
    "    end_time: str = \"\"\n",
    "    total_duration: float = 0.0\n",
    "\n",
    "class PipelineSimulator:\n",
    "    def __init__(self, pipeline_name: str, nodes: List[SimulatedNode]):\n",
    "        # TODO: Initialize simulator\n",
    "        pass\n",
    "    \n",
    "    def _topological_sort(self) -> List[str]:\n",
    "        # TODO: Implement topological sort\n",
    "        pass\n",
    "    \n",
    "    def _execute_node(self, node: SimulatedNode) -> bool:\n",
    "        \"\"\"\n",
    "        Simulate node execution.\n",
    "        \n",
    "        Returns True for success, False for failure.\n",
    "        \"\"\"\n",
    "        # TODO: Sleep for node.duration\n",
    "        # TODO: Randomly fail based on failure_rate\n",
    "        pass\n",
    "    \n",
    "    def run(self, verbose: bool = True) -> ExecutionResults:\n",
    "        \"\"\"\n",
    "        Execute pipeline with simulation.\n",
    "        \n",
    "        If verbose, print progress as nodes execute.\n",
    "        \"\"\"\n",
    "        # TODO: Implement full execution with:\n",
    "        # - Timing\n",
    "        # - Dependency checking\n",
    "        # - Failure propagation\n",
    "        # - Progress logging\n",
    "        pass\n",
    "\n",
    "# Test the simulator\n",
    "nodes = [\n",
    "    SimulatedNode(\"raw_customers\", [], duration=0.5, failure_rate=0.1),\n",
    "    SimulatedNode(\"raw_orders\", [], duration=0.5, failure_rate=0.1),\n",
    "    SimulatedNode(\"clean_customers\", [\"raw_customers\"], duration=1.0, failure_rate=0.0),\n",
    "    SimulatedNode(\"clean_orders\", [\"raw_orders\"], duration=1.0, failure_rate=0.0),\n",
    "    SimulatedNode(\"customer_orders\", [\"clean_customers\", \"clean_orders\"], duration=1.5, failure_rate=0.0),\n",
    "]\n",
    "\n",
    "simulator = PipelineSimulator(\"bronze_to_silver\", nodes)\n",
    "results = simulator.run(verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Pipeline: {results.pipeline_name}\")\n",
    "print(f\"Completed: {len(results.completed)}\")\n",
    "print(f\"Failed: {len(results.failed)}\")\n",
    "print(f\"Skipped: {len(results.skipped)}\")\n",
    "print(f\"Total Duration: {results.total_duration:.2f}s\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Exercise: Multi-Pipeline Manager\n",
    "\n",
    "Build a manager that can run multiple pipelines with dependencies between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PipelineDef:\n",
    "    name: str\n",
    "    nodes: List[str]\n",
    "    depends_on_pipelines: List[str] = field(default_factory=list)\n",
    "\n",
    "class MultiPipelineManager:\n",
    "    \"\"\"\n",
    "    Manages multiple pipelines where pipelines can depend on other pipelines.\n",
    "    \n",
    "    Example:\n",
    "        bronze_to_silver: no dependencies\n",
    "        silver_to_gold: depends on bronze_to_silver\n",
    "        analytics: depends on silver_to_gold\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pipelines: List[PipelineDef]):\n",
    "        # TODO: Store pipelines\n",
    "        pass\n",
    "    \n",
    "    def _get_pipeline_execution_order(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get execution order for pipelines based on their dependencies.\n",
    "        \"\"\"\n",
    "        # TODO: Topological sort on pipelines\n",
    "        pass\n",
    "    \n",
    "    def run(self, pipeline_names: List[str] = None) -> Dict[str, bool]:\n",
    "        \"\"\"\n",
    "        Run specified pipelines (or all if None).\n",
    "        \n",
    "        Returns dict mapping pipeline name to success status.\n",
    "        \n",
    "        If a pipeline fails, dependent pipelines are skipped.\n",
    "        \"\"\"\n",
    "        # TODO: Implement multi-pipeline execution\n",
    "        pass\n",
    "\n",
    "# Test the manager\n",
    "pipelines = [\n",
    "    PipelineDef(\"raw_ingestion\", [\"fetch_customers\", \"fetch_orders\"]),\n",
    "    PipelineDef(\"bronze_to_silver\", [\"clean_customers\", \"clean_orders\"], [\"raw_ingestion\"]),\n",
    "    PipelineDef(\"silver_to_gold\", [\"customer_orders\", \"order_metrics\"], [\"bronze_to_silver\"]),\n",
    "    PipelineDef(\"analytics\", [\"customer_analytics\", \"revenue_report\"], [\"silver_to_gold\"]),\n",
    "]\n",
    "\n",
    "manager = MultiPipelineManager(pipelines)\n",
    "\n",
    "print(\"Running all pipelines:\")\n",
    "results = manager.run()\n",
    "\n",
    "for name, success in results.items():\n",
    "    status = \"✅\" if success else \"❌\"\n",
    "    print(f\"{status} {name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
