{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Orchestration Solutions\n",
    "\n",
    "Complete solutions with detailed explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1: Simple Pipeline Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Callable\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "@dataclass\n",
    "class SimpleNodeConfig:\n",
    "    name: str\n",
    "    depends_on: List[str] = field(default_factory=list)\n",
    "    execute_fn: Callable[[], bool] = None\n",
    "\n",
    "@dataclass\n",
    "class SimplePipelineResults:\n",
    "    completed: List[str] = field(default_factory=list)\n",
    "    failed: List[str] = field(default_factory=list)\n",
    "    skipped: List[str] = field(default_factory=list)\n",
    "\n",
    "class SimplePipeline:\n",
    "    def __init__(self, nodes: List[SimpleNodeConfig]):\n",
    "        self.nodes = {node.name: node for node in nodes}\n",
    "    \n",
    "    def _topological_sort(self) -> List[str]:\n",
    "        \"\"\"Kahn's algorithm for topological sort.\"\"\"\n",
    "        # Calculate in-degrees\n",
    "        in_degree = {name: 0 for name in self.nodes}\n",
    "        for node in self.nodes.values():\n",
    "            for dep in node.depends_on:\n",
    "                in_degree[node.name] += 1\n",
    "        \n",
    "        # Find nodes with no dependencies\n",
    "        queue = deque([name for name, degree in in_degree.items() if degree == 0])\n",
    "        result = []\n",
    "        \n",
    "        while queue:\n",
    "            current = queue.popleft()\n",
    "            result.append(current)\n",
    "            \n",
    "            # Reduce in-degree for dependent nodes\n",
    "            for name, node in self.nodes.items():\n",
    "                if current in node.depends_on:\n",
    "                    in_degree[name] -= 1\n",
    "                    if in_degree[name] == 0:\n",
    "                        queue.append(name)\n",
    "        \n",
    "        if len(result) != len(self.nodes):\n",
    "            raise ValueError(\"Circular dependency detected\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def run(self) -> SimplePipelineResults:\n",
    "        \"\"\"Execute pipeline and return results.\"\"\"\n",
    "        results = SimplePipelineResults()\n",
    "        \n",
    "        # Get execution order\n",
    "        execution_order = self._topological_sort()\n",
    "        \n",
    "        # Execute nodes in order\n",
    "        for node_name in execution_order:\n",
    "            node = self.nodes[node_name]\n",
    "            \n",
    "            # Check if dependencies failed\n",
    "            deps_failed = any(dep in results.failed for dep in node.depends_on)\n",
    "            \n",
    "            if deps_failed:\n",
    "                results.skipped.append(node_name)\n",
    "                print(f\"⏭️  SKIPPED: {node_name} (dependency failed)\")\n",
    "                continue\n",
    "            \n",
    "            # Execute node\n",
    "            try:\n",
    "                success = node.execute_fn()\n",
    "                if success:\n",
    "                    results.completed.append(node_name)\n",
    "                    print(f\"✅ COMPLETED: {node_name}\")\n",
    "                else:\n",
    "                    results.failed.append(node_name)\n",
    "                    print(f\"❌ FAILED: {node_name}\")\n",
    "            except Exception as e:\n",
    "                results.failed.append(node_name)\n",
    "                print(f\"❌ FAILED: {node_name} - {str(e)}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test\n",
    "nodes = [\n",
    "    SimpleNodeConfig(\"A\", [], lambda: True),\n",
    "    SimpleNodeConfig(\"B\", [], lambda: False),\n",
    "    SimpleNodeConfig(\"C\", [\"A\"], lambda: True),\n",
    "    SimpleNodeConfig(\"D\", [\"B\"], lambda: True),\n",
    "    SimpleNodeConfig(\"E\", [\"C\", \"D\"], lambda: True),\n",
    "]\n",
    "\n",
    "pipeline = SimplePipeline(nodes)\n",
    "results = pipeline.run()\n",
    "\n",
    "print(f\"\\nCompleted: {results.completed}\")\n",
    "print(f\"Failed: {results.failed}\")\n",
    "print(f\"Skipped: {results.skipped}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2: Layer Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_execution_layers(nodes: Dict[str, List[str]]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Group nodes into layers for parallel execution.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Layer 0: nodes with no dependencies\n",
    "    2. Layer N: nodes whose dependencies are all in layers 0..N-1\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    processed = set()\n",
    "    remaining = set(nodes.keys())\n",
    "    \n",
    "    while remaining:\n",
    "        # Find nodes where all dependencies are processed\n",
    "        current_layer = []\n",
    "        for node in remaining:\n",
    "            deps = nodes[node]\n",
    "            if all(dep in processed for dep in deps):\n",
    "                current_layer.append(node)\n",
    "        \n",
    "        if not current_layer:\n",
    "            raise ValueError(\"Circular dependency detected\")\n",
    "        \n",
    "        layers.append(current_layer)\n",
    "        processed.update(current_layer)\n",
    "        remaining -= set(current_layer)\n",
    "    \n",
    "    return layers\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        'nodes': {'A': [], 'B': [], 'C': ['A'], 'D': ['A', 'B'], 'E': ['C', 'D']},\n",
    "        'expected': [['A', 'B'], ['C', 'D'], ['E']]\n",
    "    },\n",
    "    {\n",
    "        'nodes': {'A': [], 'B': ['A'], 'C': ['B'], 'D': ['C']},\n",
    "        'expected': [['A'], ['B'], ['C'], ['D']]\n",
    "    },\n",
    "    {\n",
    "        'nodes': {'A': [], 'B': [], 'C': [], 'D': ['A', 'B', 'C']},\n",
    "        'expected': [['A', 'B', 'C'], ['D']]\n",
    "    },\n",
    "]\n",
    "\n",
    "for i, test in enumerate(test_cases, 1):\n",
    "    result = get_execution_layers(test['nodes'])\n",
    "    result_sorted = [sorted(layer) for layer in result]\n",
    "    expected_sorted = [sorted(layer) for layer in test['expected']]\n",
    "    \n",
    "    if result_sorted == expected_sorted:\n",
    "        print(f\"✅ Test {i} passed\")\n",
    "        print(f\"   Layers: {result}\")\n",
    "    else:\n",
    "        print(f\"❌ Test {i} failed\")\n",
    "        print(f\"   Expected: {expected_sorted}\")\n",
    "        print(f\"   Got: {result_sorted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 3: PipelineResults Aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PipelineRun:\n",
    "    pipeline_name: str\n",
    "    completed: List[str]\n",
    "    failed: List[str]\n",
    "    skipped: List[str]\n",
    "    duration: float\n",
    "\n",
    "@dataclass\n",
    "class AggregatedResults:\n",
    "    total_pipelines: int\n",
    "    successful_pipelines: int\n",
    "    failed_pipelines: int\n",
    "    total_nodes: int\n",
    "    total_completed: int\n",
    "    total_failed: int\n",
    "    total_skipped: int\n",
    "    total_duration: float\n",
    "    \n",
    "    def success_rate(self) -> float:\n",
    "        if self.total_nodes == 0:\n",
    "            return 0.0\n",
    "        return (self.total_completed / self.total_nodes) * 100\n",
    "\n",
    "def aggregate_pipeline_results(runs: List[PipelineRun]) -> AggregatedResults:\n",
    "    \"\"\"\n",
    "    Aggregate results from multiple pipeline runs.\n",
    "    \"\"\"\n",
    "    total_pipelines = len(runs)\n",
    "    successful_pipelines = sum(1 for run in runs if len(run.failed) == 0)\n",
    "    failed_pipelines = total_pipelines - successful_pipelines\n",
    "    \n",
    "    total_completed = sum(len(run.completed) for run in runs)\n",
    "    total_failed = sum(len(run.failed) for run in runs)\n",
    "    total_skipped = sum(len(run.skipped) for run in runs)\n",
    "    total_nodes = total_completed + total_failed + total_skipped\n",
    "    \n",
    "    total_duration = sum(run.duration for run in runs)\n",
    "    \n",
    "    return AggregatedResults(\n",
    "        total_pipelines=total_pipelines,\n",
    "        successful_pipelines=successful_pipelines,\n",
    "        failed_pipelines=failed_pipelines,\n",
    "        total_nodes=total_nodes,\n",
    "        total_completed=total_completed,\n",
    "        total_failed=total_failed,\n",
    "        total_skipped=total_skipped,\n",
    "        total_duration=total_duration,\n",
    "    )\n",
    "\n",
    "# Test\n",
    "runs = [\n",
    "    PipelineRun(\n",
    "        pipeline_name=\"bronze_to_silver\",\n",
    "        completed=[\"A\", \"B\", \"C\"],\n",
    "        failed=[],\n",
    "        skipped=[],\n",
    "        duration=10.5\n",
    "    ),\n",
    "    PipelineRun(\n",
    "        pipeline_name=\"silver_to_gold\",\n",
    "        completed=[\"D\", \"E\"],\n",
    "        failed=[\"F\"],\n",
    "        skipped=[\"G\", \"H\"],\n",
    "        duration=5.2\n",
    "    ),\n",
    "    PipelineRun(\n",
    "        pipeline_name=\"gold_analytics\",\n",
    "        completed=[\"I\", \"J\", \"K\", \"L\"],\n",
    "        failed=[],\n",
    "        skipped=[],\n",
    "        duration=8.3\n",
    "    ),\n",
    "]\n",
    "\n",
    "agg = aggregate_pipeline_results(runs)\n",
    "\n",
    "print(\"Aggregated Results:\")\n",
    "print(f\"  Total Pipelines: {agg.total_pipelines}\")\n",
    "print(f\"  Successful: {agg.successful_pipelines}\")\n",
    "print(f\"  Failed: {agg.failed_pipelines}\")\n",
    "print(f\"  Total Nodes: {agg.total_nodes}\")\n",
    "print(f\"  Completed: {agg.total_completed}\")\n",
    "print(f\"  Failed: {agg.total_failed}\")\n",
    "print(f\"  Skipped: {agg.total_skipped}\")\n",
    "print(f\"  Total Duration: {agg.total_duration:.1f}s\")\n",
    "print(f\"  Success Rate: {agg.success_rate():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 4: Pipeline Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ValidationResult:\n",
    "    valid: bool\n",
    "    errors: List[str] = field(default_factory=list)\n",
    "    warnings: List[str] = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class NodeDef:\n",
    "    name: str\n",
    "    depends_on: List[str]\n",
    "    connection: str\n",
    "\n",
    "def validate_pipeline(\n",
    "    nodes: List[NodeDef],\n",
    "    available_connections: List[str]\n",
    ") -> ValidationResult:\n",
    "    \"\"\"\n",
    "    Comprehensive pipeline validation.\n",
    "    \"\"\"\n",
    "    result = ValidationResult(valid=True)\n",
    "    \n",
    "    # Check for duplicate node names\n",
    "    names = [node.name for node in nodes]\n",
    "    duplicates = set([name for name in names if names.count(name) > 1])\n",
    "    if duplicates:\n",
    "        result.valid = False\n",
    "        result.errors.append(f\"Duplicate node names: {duplicates}\")\n",
    "    \n",
    "    # Build node map\n",
    "    node_map = {node.name: node for node in nodes}\n",
    "    \n",
    "    # Check for missing dependencies\n",
    "    for node in nodes:\n",
    "        for dep in node.depends_on:\n",
    "            if dep not in node_map:\n",
    "                result.valid = False\n",
    "                result.errors.append(f\"Node '{node.name}': dependency '{dep}' does not exist\")\n",
    "    \n",
    "    # Check for circular dependencies (if no errors so far)\n",
    "    if result.valid:\n",
    "        try:\n",
    "            _topological_sort(node_map)\n",
    "        except ValueError as e:\n",
    "            result.valid = False\n",
    "            result.errors.append(str(e))\n",
    "    \n",
    "    # Check connections (warnings only)\n",
    "    for node in nodes:\n",
    "        if node.connection not in available_connections:\n",
    "            result.warnings.append(\n",
    "                f\"Node '{node.name}': connection '{node.connection}' not available\"\n",
    "            )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def _topological_sort(node_map: Dict[str, NodeDef]) -> List[str]:\n",
    "    \"\"\"Helper to detect circular dependencies.\"\"\"\n",
    "    in_degree = {name: 0 for name in node_map}\n",
    "    for node in node_map.values():\n",
    "        for dep in node.depends_on:\n",
    "            if dep in in_degree:\n",
    "                in_degree[node.name] += 1\n",
    "    \n",
    "    queue = deque([name for name, degree in in_degree.items() if degree == 0])\n",
    "    result = []\n",
    "    \n",
    "    while queue:\n",
    "        current = queue.popleft()\n",
    "        result.append(current)\n",
    "        \n",
    "        for name, node in node_map.items():\n",
    "            if current in node.depends_on:\n",
    "                in_degree[name] -= 1\n",
    "                if in_degree[name] == 0:\n",
    "                    queue.append(name)\n",
    "    \n",
    "    if len(result) != len(node_map):\n",
    "        raise ValueError(\"Circular dependency detected\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Tests\n",
    "test_valid = [\n",
    "    NodeDef(\"A\", [], \"local\"),\n",
    "    NodeDef(\"B\", [\"A\"], \"local\"),\n",
    "    NodeDef(\"C\", [\"B\"], \"azure\"),\n",
    "]\n",
    "\n",
    "test_circular = [\n",
    "    NodeDef(\"A\", [\"B\"], \"local\"),\n",
    "    NodeDef(\"B\", [\"C\"], \"local\"),\n",
    "    NodeDef(\"C\", [\"A\"], \"local\"),\n",
    "]\n",
    "\n",
    "test_missing_dep = [\n",
    "    NodeDef(\"A\", [], \"local\"),\n",
    "    NodeDef(\"B\", [\"X\"], \"local\"),\n",
    "]\n",
    "\n",
    "test_duplicate = [\n",
    "    NodeDef(\"A\", [], \"local\"),\n",
    "    NodeDef(\"A\", [], \"local\"),\n",
    "]\n",
    "\n",
    "connections = [\"local\", \"azure\"]\n",
    "\n",
    "print(\"Test 1 - Valid pipeline:\")\n",
    "result = validate_pipeline(test_valid, connections)\n",
    "print(f\"  Valid: {result.valid}\")\n",
    "print(f\"  Errors: {result.errors}\")\n",
    "print(f\"  Warnings: {result.warnings}\")\n",
    "\n",
    "print(\"\\nTest 2 - Circular dependency:\")\n",
    "result = validate_pipeline(test_circular, connections)\n",
    "print(f\"  Valid: {result.valid}\")\n",
    "print(f\"  Errors: {result.errors}\")\n",
    "\n",
    "print(\"\\nTest 3 - Missing dependency:\")\n",
    "result = validate_pipeline(test_missing_dep, connections)\n",
    "print(f\"  Valid: {result.valid}\")\n",
    "print(f\"  Errors: {result.errors}\")\n",
    "\n",
    "print(\"\\nTest 4 - Duplicate nodes:\")\n",
    "result = validate_pipeline(test_duplicate, connections)\n",
    "print(f\"  Valid: {result.valid}\")\n",
    "print(f\"  Errors: {result.errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 5: Pipeline Execution Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "@dataclass\n",
    "class SimulatedNode:\n",
    "    name: str\n",
    "    depends_on: List[str]\n",
    "    duration: float\n",
    "    failure_rate: float\n",
    "\n",
    "@dataclass\n",
    "class ExecutionResults:\n",
    "    pipeline_name: str\n",
    "    completed: List[str] = field(default_factory=list)\n",
    "    failed: List[str] = field(default_factory=list)\n",
    "    skipped: List[str] = field(default_factory=list)\n",
    "    node_durations: Dict[str, float] = field(default_factory=dict)\n",
    "    start_time: str = \"\"\n",
    "    end_time: str = \"\"\n",
    "    total_duration: float = 0.0\n",
    "\n",
    "class PipelineSimulator:\n",
    "    def __init__(self, pipeline_name: str, nodes: List[SimulatedNode]):\n",
    "        self.pipeline_name = pipeline_name\n",
    "        self.nodes = {node.name: node for node in nodes}\n",
    "    \n",
    "    def _topological_sort(self) -> List[str]:\n",
    "        in_degree = {name: 0 for name in self.nodes}\n",
    "        for node in self.nodes.values():\n",
    "            for dep in node.depends_on:\n",
    "                in_degree[node.name] += 1\n",
    "        \n",
    "        queue = deque([name for name, degree in in_degree.items() if degree == 0])\n",
    "        result = []\n",
    "        \n",
    "        while queue:\n",
    "            current = queue.popleft()\n",
    "            result.append(current)\n",
    "            \n",
    "            for name, node in self.nodes.items():\n",
    "                if current in node.depends_on:\n",
    "                    in_degree[name] -= 1\n",
    "                    if in_degree[name] == 0:\n",
    "                        queue.append(name)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _execute_node(self, node: SimulatedNode) -> bool:\n",
    "        \"\"\"Simulate node execution with random failure.\"\"\"\n",
    "        time.sleep(node.duration)\n",
    "        return random.random() > node.failure_rate\n",
    "    \n",
    "    def run(self, verbose: bool = True) -> ExecutionResults:\n",
    "        \"\"\"Execute pipeline with simulation.\"\"\"\n",
    "        start = time.time()\n",
    "        results = ExecutionResults(\n",
    "            pipeline_name=self.pipeline_name,\n",
    "            start_time=datetime.now().isoformat()\n",
    "        )\n",
    "        \n",
    "        # Get execution order\n",
    "        execution_order = self._topological_sort()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nExecuting pipeline: {self.pipeline_name}\")\n",
    "            print(f\"Execution order: {' → '.join(execution_order)}\\n\")\n",
    "        \n",
    "        # Execute nodes\n",
    "        for node_name in execution_order:\n",
    "            node = self.nodes[node_name]\n",
    "            \n",
    "            # Check dependencies\n",
    "            deps_failed = any(dep in results.failed for dep in node.depends_on)\n",
    "            \n",
    "            if deps_failed:\n",
    "                results.skipped.append(node_name)\n",
    "                if verbose:\n",
    "                    print(f\"⏭️  SKIPPED: {node_name} (dependency failed)\")\n",
    "                continue\n",
    "            \n",
    "            # Execute\n",
    "            if verbose:\n",
    "                print(f\"⚙️  EXECUTING: {node_name} ({node.duration}s)...\", end=\" \")\n",
    "            \n",
    "            node_start = time.time()\n",
    "            success = self._execute_node(node)\n",
    "            node_duration = time.time() - node_start\n",
    "            results.node_durations[node_name] = node_duration\n",
    "            \n",
    "            if success:\n",
    "                results.completed.append(node_name)\n",
    "                if verbose:\n",
    "                    print(\"✅ COMPLETED\")\n",
    "            else:\n",
    "                results.failed.append(node_name)\n",
    "                if verbose:\n",
    "                    print(\"❌ FAILED\")\n",
    "        \n",
    "        # Finalize results\n",
    "        results.total_duration = time.time() - start\n",
    "        results.end_time = datetime.now().isoformat()\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test the simulator\n",
    "nodes = [\n",
    "    SimulatedNode(\"raw_customers\", [], duration=0.5, failure_rate=0.1),\n",
    "    SimulatedNode(\"raw_orders\", [], duration=0.5, failure_rate=0.1),\n",
    "    SimulatedNode(\"clean_customers\", [\"raw_customers\"], duration=1.0, failure_rate=0.0),\n",
    "    SimulatedNode(\"clean_orders\", [\"raw_orders\"], duration=1.0, failure_rate=0.0),\n",
    "    SimulatedNode(\"customer_orders\", [\"clean_customers\", \"clean_orders\"], duration=1.5, failure_rate=0.0),\n",
    "]\n",
    "\n",
    "simulator = PipelineSimulator(\"bronze_to_silver\", nodes)\n",
    "results = simulator.run(verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Pipeline: {results.pipeline_name}\")\n",
    "print(f\"Completed: {len(results.completed)} {results.completed}\")\n",
    "print(f\"Failed: {len(results.failed)} {results.failed}\")\n",
    "print(f\"Skipped: {len(results.skipped)} {results.skipped}\")\n",
    "print(f\"Total Duration: {results.total_duration:.2f}s\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Solution: Multi-Pipeline Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PipelineDef:\n",
    "    name: str\n",
    "    nodes: List[str]\n",
    "    depends_on_pipelines: List[str] = field(default_factory=list)\n",
    "\n",
    "class MultiPipelineManager:\n",
    "    def __init__(self, pipelines: List[PipelineDef]):\n",
    "        self.pipelines = {p.name: p for p in pipelines}\n",
    "    \n",
    "    def _get_pipeline_execution_order(self) -> List[str]:\n",
    "        \"\"\"Topological sort on pipelines.\"\"\"\n",
    "        in_degree = {name: 0 for name in self.pipelines}\n",
    "        for pipeline in self.pipelines.values():\n",
    "            for dep in pipeline.depends_on_pipelines:\n",
    "                in_degree[pipeline.name] += 1\n",
    "        \n",
    "        queue = deque([name for name, degree in in_degree.items() if degree == 0])\n",
    "        result = []\n",
    "        \n",
    "        while queue:\n",
    "            current = queue.popleft()\n",
    "            result.append(current)\n",
    "            \n",
    "            for name, pipeline in self.pipelines.items():\n",
    "                if current in pipeline.depends_on_pipelines:\n",
    "                    in_degree[name] -= 1\n",
    "                    if in_degree[name] == 0:\n",
    "                        queue.append(name)\n",
    "        \n",
    "        if len(result) != len(self.pipelines):\n",
    "            raise ValueError(\"Circular pipeline dependency\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def run(self, pipeline_names: List[str] = None) -> Dict[str, bool]:\n",
    "        \"\"\"Run pipelines in dependency order.\"\"\"\n",
    "        # Determine which pipelines to run\n",
    "        if pipeline_names is None:\n",
    "            to_run = self._get_pipeline_execution_order()\n",
    "        else:\n",
    "            # Get dependencies and order them\n",
    "            all_needed = set()\n",
    "            for name in pipeline_names:\n",
    "                self._collect_dependencies(name, all_needed)\n",
    "            \n",
    "            all_order = self._get_pipeline_execution_order()\n",
    "            to_run = [p for p in all_order if p in all_needed]\n",
    "        \n",
    "        # Execute pipelines\n",
    "        results = {}\n",
    "        failed_pipelines = set()\n",
    "        \n",
    "        for name in to_run:\n",
    "            pipeline = self.pipelines[name]\n",
    "            \n",
    "            # Check if dependencies failed\n",
    "            deps_failed = any(dep in failed_pipelines for dep in pipeline.depends_on_pipelines)\n",
    "            \n",
    "            if deps_failed:\n",
    "                print(f\"⏭️  SKIPPED: {name} (pipeline dependency failed)\")\n",
    "                results[name] = False\n",
    "                failed_pipelines.add(name)\n",
    "                continue\n",
    "            \n",
    "            # Simulate pipeline execution\n",
    "            print(f\"⚙️  RUNNING: {name} ({len(pipeline.nodes)} nodes)\")\n",
    "            success = random.random() > 0.2  # 20% failure rate\n",
    "            \n",
    "            if success:\n",
    "                print(f\"✅ COMPLETED: {name}\")\n",
    "                results[name] = True\n",
    "            else:\n",
    "                print(f\"❌ FAILED: {name}\")\n",
    "                results[name] = False\n",
    "                failed_pipelines.add(name)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _collect_dependencies(self, pipeline_name: str, collected: set):\n",
    "        \"\"\"Recursively collect all dependencies.\"\"\"\n",
    "        if pipeline_name in collected:\n",
    "            return\n",
    "        \n",
    "        collected.add(pipeline_name)\n",
    "        pipeline = self.pipelines[pipeline_name]\n",
    "        \n",
    "        for dep in pipeline.depends_on_pipelines:\n",
    "            self._collect_dependencies(dep, collected)\n",
    "\n",
    "# Test\n",
    "pipelines = [\n",
    "    PipelineDef(\"raw_ingestion\", [\"fetch_customers\", \"fetch_orders\"]),\n",
    "    PipelineDef(\"bronze_to_silver\", [\"clean_customers\", \"clean_orders\"], [\"raw_ingestion\"]),\n",
    "    PipelineDef(\"silver_to_gold\", [\"customer_orders\", \"order_metrics\"], [\"bronze_to_silver\"]),\n",
    "    PipelineDef(\"analytics\", [\"customer_analytics\", \"revenue_report\"], [\"silver_to_gold\"]),\n",
    "]\n",
    "\n",
    "manager = MultiPipelineManager(pipelines)\n",
    "\n",
    "print(\"Running all pipelines:\\n\")\n",
    "results = manager.run()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Results:\")\n",
    "for name, success in results.items():\n",
    "    status = \"✅\" if success else \"❌\"\n",
    "    print(f\"{status} {name}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
