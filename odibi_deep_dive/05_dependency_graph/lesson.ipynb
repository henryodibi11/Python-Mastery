{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Graph Deep Dive\n",
    "\n",
    "## ðŸŽ¯ Mission\n",
    "Build a complete `DependencyGraph` class from scratch by reading and understanding the actual Odibi implementation.\n",
    "\n",
    "**Source:** `Odibi/odibi/graph.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding the Problem\n",
    "\n",
    "### The Challenge\n",
    "You have pipeline nodes with dependencies:\n",
    "```python\n",
    "nodes = [\n",
    "    NodeConfig(name='extract', depends_on=[]),\n",
    "    NodeConfig(name='clean', depends_on=['extract']),\n",
    "    NodeConfig(name='validate', depends_on=['extract']),\n",
    "    NodeConfig(name='aggregate', depends_on=['clean']),\n",
    "    NodeConfig(name='report', depends_on=['aggregate'])\n",
    "]\n",
    "```\n",
    "\n",
    "### Questions to Answer\n",
    "1. What order should nodes execute?\n",
    "2. Which nodes can run in parallel?\n",
    "3. Are there any circular dependencies?\n",
    "4. What happens if a dependency doesn't exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Simplified NodeConfig for this lesson\n",
    "from typing import List, Set, Dict, Optional\n",
    "from collections import defaultdict, deque\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class NodeConfig:\n",
    "    name: str\n",
    "    depends_on: List[str]\n",
    "\n",
    "class DependencyError(Exception):\n",
    "    \"\"\"Custom exception for dependency issues.\"\"\"\n",
    "    def __init__(self, message: str, cycle: Optional[List[str]] = None):\n",
    "        super().__init__(message)\n",
    "        self.cycle = cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Graph Construction\n",
    "\n",
    "### First Principles: Adjacency Lists\n",
    "\n",
    "Two representations:\n",
    "1. **Forward (adjacency_list)**: `node â†’ [dependents]`\n",
    "   - \"Who needs me?\"\n",
    "   - Used for: topological sort, execution layers\n",
    "\n",
    "2. **Reverse (reverse_adjacency_list)**: `node â†’ [dependencies]`\n",
    "   - \"Who do I need?\"\n",
    "   - Used for: finding all dependencies\n",
    "\n",
    "### The Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DependencyGraph:\n",
    "    \"\"\"Builds and analyzes dependency graph from node configurations.\"\"\"\n",
    "    \n",
    "    def __init__(self, nodes: List[NodeConfig]):\n",
    "        \"\"\"Initialize dependency graph.\n",
    "        \n",
    "        Args:\n",
    "            nodes: List of node configurations\n",
    "        \"\"\"\n",
    "        # Store nodes by name for O(1) lookup\n",
    "        self.nodes = {node.name: node for node in nodes}\n",
    "        \n",
    "        # Forward edges: dependency â†’ dependents\n",
    "        self.adjacency_list: Dict[str, List[str]] = defaultdict(list)\n",
    "        \n",
    "        # Reverse edges: dependent â†’ dependencies\n",
    "        self.reverse_adjacency_list: Dict[str, List[str]] = defaultdict(list)\n",
    "        \n",
    "        self._build_graph()\n",
    "        self._validate_graph()\n",
    "    \n",
    "    def _build_graph(self) -> None:\n",
    "        \"\"\"Build adjacency lists from node dependencies.\"\"\"\n",
    "        for node in self.nodes.values():\n",
    "            for dependency in node.depends_on:\n",
    "                # Edge from dependency to node (dependency â†’ node)\n",
    "                self.adjacency_list[dependency].append(node.name)\n",
    "                self.reverse_adjacency_list[node.name].append(dependency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§ª Test Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple test pipeline\n",
    "nodes = [\n",
    "    NodeConfig('A', []),\n",
    "    NodeConfig('B', ['A']),\n",
    "    NodeConfig('C', ['A']),\n",
    "    NodeConfig('D', ['B', 'C'])\n",
    "]\n",
    "\n",
    "# Temporarily skip validation to test construction\n",
    "class PartialGraph(DependencyGraph):\n",
    "    def _validate_graph(self): pass\n",
    "\n",
    "graph = PartialGraph(nodes)\n",
    "\n",
    "print(\"Forward (adjacency_list):\")\n",
    "for node, dependents in graph.adjacency_list.items():\n",
    "    print(f\"  {node} â†’ {dependents}\")\n",
    "\n",
    "print(\"\\nReverse (reverse_adjacency_list):\")\n",
    "for node, deps in graph.reverse_adjacency_list.items():\n",
    "    print(f\"  {node} â† {deps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Validation\n",
    "\n",
    "### Two Critical Checks\n",
    "\n",
    "1. **Missing Dependencies**: All `depends_on` must reference existing nodes\n",
    "2. **Cycles**: No circular dependencies (A â†’ B â†’ C â†’ A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_graph(self) -> None:\n",
    "    \"\"\"Validate the dependency graph.\n",
    "    \n",
    "    Raises:\n",
    "        DependencyError: If validation fails\n",
    "    \"\"\"\n",
    "    self._check_missing_dependencies()\n",
    "    self._check_cycles()\n",
    "\n",
    "def _check_missing_dependencies(self) -> None:\n",
    "    \"\"\"Check that all dependencies exist as nodes.\n",
    "    \n",
    "    Raises:\n",
    "        DependencyError: If any dependency doesn't exist\n",
    "    \"\"\"\n",
    "    missing_deps = []\n",
    "    \n",
    "    for node in self.nodes.values():\n",
    "        for dependency in node.depends_on:\n",
    "            if dependency not in self.nodes:\n",
    "                missing_deps.append((node.name, dependency))\n",
    "    \n",
    "    if missing_deps:\n",
    "        errors = [\n",
    "            f\"Node '{node}' depends on '{dep}' which doesn't exist\"\n",
    "            for node, dep in missing_deps\n",
    "        ]\n",
    "        raise DependencyError(\"Missing dependencies found:\\n  \" + \"\\n  \".join(errors))\n",
    "\n",
    "# Add to DependencyGraph class\n",
    "DependencyGraph._validate_graph = _validate_graph\n",
    "DependencyGraph._check_missing_dependencies = _check_missing_dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle Detection with DFS\n",
    "\n",
    "**Algorithm:**\n",
    "1. Track visited nodes (grey = in current path, black = fully processed)\n",
    "2. For each node, DFS through dependents\n",
    "3. If we encounter a grey node, cycle found\n",
    "4. Return the cycle path for helpful error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_cycles(self) -> None:\n",
    "    \"\"\"Check for circular dependencies.\n",
    "    \n",
    "    Raises:\n",
    "        DependencyError: If cycle detected\n",
    "    \"\"\"\n",
    "    visited = set()  # Fully processed (black)\n",
    "    rec_stack = set()  # Currently processing (grey)\n",
    "    \n",
    "    def visit(node: str, path: List[str]) -> Optional[List[str]]:\n",
    "        \"\"\"DFS to detect cycles.\n",
    "        \n",
    "        Returns:\n",
    "            Cycle path if found, None otherwise\n",
    "        \"\"\"\n",
    "        if node in rec_stack:\n",
    "            # Found a cycle - extract it from path\n",
    "            cycle_start = path.index(node)\n",
    "            return path[cycle_start:] + [node]\n",
    "        \n",
    "        if node in visited:\n",
    "            return None  # Already fully processed\n",
    "        \n",
    "        visited.add(node)\n",
    "        rec_stack.add(node)\n",
    "        path.append(node)\n",
    "        \n",
    "        # Visit all dependents\n",
    "        for dependent in self.adjacency_list[node]:\n",
    "            cycle = visit(dependent, path[:])\n",
    "            if cycle:\n",
    "                return cycle\n",
    "        \n",
    "        rec_stack.remove(node)\n",
    "        return None\n",
    "    \n",
    "    # Check from each node (handles disconnected components)\n",
    "    for node_name in self.nodes.keys():\n",
    "        if node_name not in visited:\n",
    "            cycle = visit(node_name, [])\n",
    "            if cycle:\n",
    "                raise DependencyError(\n",
    "                    \"Circular dependency detected\",\n",
    "                    cycle=cycle\n",
    "                )\n",
    "\n",
    "# Add to DependencyGraph class\n",
    "DependencyGraph._check_cycles = _check_cycles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§ª Test Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Missing dependency\n",
    "try:\n",
    "    bad_nodes = [NodeConfig('A', ['MISSING'])]\n",
    "    graph = DependencyGraph(bad_nodes)\n",
    "except DependencyError as e:\n",
    "    print(\"âœ“ Caught missing dependency:\")\n",
    "    print(f\"  {e}\")\n",
    "\n",
    "# Test 2: Cycle detection\n",
    "try:\n",
    "    cycle_nodes = [\n",
    "        NodeConfig('A', ['C']),\n",
    "        NodeConfig('B', ['A']),\n",
    "        NodeConfig('C', ['B'])\n",
    "    ]\n",
    "    graph = DependencyGraph(cycle_nodes)\n",
    "except DependencyError as e:\n",
    "    print(\"\\nâœ“ Caught cycle:\")\n",
    "    print(f\"  {e}\")\n",
    "    print(f\"  Cycle: {' â†’ '.join(e.cycle)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Topological Sort\n",
    "\n",
    "### Kahn's Algorithm\n",
    "\n",
    "**Goal:** Find a valid execution order where all dependencies run before dependents.\n",
    "\n",
    "**Algorithm:**\n",
    "1. Calculate in-degree (number of dependencies) for each node\n",
    "2. Add all nodes with in-degree 0 to queue\n",
    "3. Process queue:\n",
    "   - Remove node from queue\n",
    "   - Add to result\n",
    "   - Decrease in-degree for all dependents\n",
    "   - Add dependents with in-degree 0 to queue\n",
    "4. If not all nodes processed, cycle exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(self) -> List[str]:\n",
    "    \"\"\"Return nodes in topological order (dependencies first).\n",
    "    \n",
    "    Uses Kahn's algorithm.\n",
    "    \n",
    "    Returns:\n",
    "        List of node names in execution order\n",
    "    \"\"\"\n",
    "    # Calculate in-degree for each node\n",
    "    in_degree = {name: 0 for name in self.nodes.keys()}\n",
    "    for node in self.nodes.values():\n",
    "        for dependency in node.depends_on:\n",
    "            in_degree[node.name] += 1\n",
    "    \n",
    "    # Queue of nodes with no dependencies\n",
    "    queue = deque([name for name, degree in in_degree.items() if degree == 0])\n",
    "    sorted_nodes = []\n",
    "    \n",
    "    while queue:\n",
    "        # Process node with no remaining dependencies\n",
    "        node_name = queue.popleft()\n",
    "        sorted_nodes.append(node_name)\n",
    "        \n",
    "        # Reduce in-degree for all dependents\n",
    "        for dependent in self.adjacency_list[node_name]:\n",
    "            in_degree[dependent] -= 1\n",
    "            if in_degree[dependent] == 0:\n",
    "                queue.append(dependent)\n",
    "    \n",
    "    # If we didn't process all nodes, there's a cycle\n",
    "    if len(sorted_nodes) != len(self.nodes):\n",
    "        raise DependencyError(\"Failed to create topological sort (likely cycle)\")\n",
    "    \n",
    "    return sorted_nodes\n",
    "\n",
    "# Add to DependencyGraph class\n",
    "DependencyGraph.topological_sort = topological_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§ª Test Topological Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [\n",
    "    NodeConfig('extract', []),\n",
    "    NodeConfig('clean', ['extract']),\n",
    "    NodeConfig('validate', ['extract']),\n",
    "    NodeConfig('aggregate', ['clean']),\n",
    "    NodeConfig('report', ['aggregate', 'validate'])\n",
    "]\n",
    "\n",
    "graph = DependencyGraph(nodes)\n",
    "order = graph.topological_sort()\n",
    "\n",
    "print(\"Execution order:\")\n",
    "for i, node in enumerate(order, 1):\n",
    "    deps = graph.nodes[node].depends_on\n",
    "    deps_str = f\" (after: {', '.join(deps)})\" if deps else \" (no dependencies)\"\n",
    "    print(f\"{i}. {node}{deps_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Execution Layers (Parallel Execution)\n",
    "\n",
    "### The Insight\n",
    "\n",
    "Topological sort gives us *an* order, but not necessarily the *optimal* parallel execution plan.\n",
    "\n",
    "**Execution layers** group nodes that can run simultaneously:\n",
    "- All nodes in a layer have no dependencies on each other\n",
    "- All nodes in layer N depend only on layers 1..N-1\n",
    "\n",
    "### Algorithm\n",
    "Similar to topological sort, but collect all ready nodes at once instead of processing one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_execution_layers(self) -> List[List[str]]:\n",
    "    \"\"\"Group nodes into execution layers for parallel execution.\n",
    "    \n",
    "    Nodes in the same layer have no dependencies on each other\n",
    "    and can run in parallel.\n",
    "    \n",
    "    Returns:\n",
    "        List of layers, where each layer is a list of node names\n",
    "    \"\"\"\n",
    "    # Calculate in-degree for each node\n",
    "    in_degree = {name: len(node.depends_on) for name, node in self.nodes.items()}\n",
    "    \n",
    "    layers = []\n",
    "    remaining = set(self.nodes.keys())\n",
    "    \n",
    "    while remaining:\n",
    "        # Find all nodes with no remaining dependencies\n",
    "        current_layer = [name for name in remaining if in_degree[name] == 0]\n",
    "        \n",
    "        if not current_layer:\n",
    "            raise DependencyError(\"Cannot create execution layers (likely cycle)\")\n",
    "        \n",
    "        layers.append(current_layer)\n",
    "        \n",
    "        # Remove current layer from remaining\n",
    "        for node_name in current_layer:\n",
    "            remaining.remove(node_name)\n",
    "            \n",
    "            # Reduce in-degree for dependents\n",
    "            for dependent in self.adjacency_list[node_name]:\n",
    "                if dependent in remaining:\n",
    "                    in_degree[dependent] -= 1\n",
    "    \n",
    "    return layers\n",
    "\n",
    "# Add to DependencyGraph class\n",
    "DependencyGraph.get_execution_layers = get_execution_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§ª Test Execution Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = graph.get_execution_layers()\n",
    "\n",
    "print(\"Execution layers (nodes in same layer run in parallel):\\n\")\n",
    "for i, layer in enumerate(layers, 1):\n",
    "    print(f\"Layer {i}: {layer}\")\n",
    "    if len(layer) > 1:\n",
    "        print(f\"  â†’ Can run {len(layer)} nodes in parallel!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Dependency Queries\n",
    "\n",
    "### get_dependencies: \"What does this node need?\"\n",
    "\n",
    "BFS traversal backward through reverse adjacency list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dependencies(self, node_name: str) -> Set[str]:\n",
    "    \"\"\"Get all dependencies (direct and transitive) for a node.\n",
    "    \n",
    "    Args:\n",
    "        node_name: Name of node\n",
    "    \n",
    "    Returns:\n",
    "        Set of all dependency node names\n",
    "    \"\"\"\n",
    "    if node_name not in self.nodes:\n",
    "        raise ValueError(f\"Node '{node_name}' not found\")\n",
    "    \n",
    "    dependencies = set()\n",
    "    queue = deque([node_name])\n",
    "    \n",
    "    while queue:\n",
    "        current = queue.popleft()\n",
    "        for dependency in self.reverse_adjacency_list[current]:\n",
    "            if dependency not in dependencies:\n",
    "                dependencies.add(dependency)\n",
    "                queue.append(dependency)\n",
    "    \n",
    "    return dependencies\n",
    "\n",
    "# Add to DependencyGraph class\n",
    "DependencyGraph.get_dependencies = get_dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_dependents: \"What needs this node?\"\n",
    "\n",
    "BFS traversal forward through adjacency list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dependents(self, node_name: str) -> Set[str]:\n",
    "    \"\"\"Get all dependents (direct and transitive) for a node.\n",
    "    \n",
    "    Args:\n",
    "        node_name: Name of node\n",
    "    \n",
    "    Returns:\n",
    "        Set of all dependent node names\n",
    "    \"\"\"\n",
    "    if node_name not in self.nodes:\n",
    "        raise ValueError(f\"Node '{node_name}' not found\")\n",
    "    \n",
    "    dependents = set()\n",
    "    queue = deque([node_name])\n",
    "    \n",
    "    while queue:\n",
    "        current = queue.popleft()\n",
    "        for dependent in self.adjacency_list[current]:\n",
    "            if dependent not in dependents:\n",
    "                dependents.add(dependent)\n",
    "                queue.append(dependent)\n",
    "    \n",
    "    return dependents\n",
    "\n",
    "# Add to DependencyGraph class\n",
    "DependencyGraph.get_dependents = get_dependents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_independent_nodes: Entry points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_independent_nodes(self) -> List[str]:\n",
    "    \"\"\"Get nodes that have no dependencies.\n",
    "    \n",
    "    Returns:\n",
    "        List of node names with no dependencies\n",
    "    \"\"\"\n",
    "    return [name for name, node in self.nodes.items() if not node.depends_on]\n",
    "\n",
    "# Add to DependencyGraph class\n",
    "DependencyGraph.get_independent_nodes = get_independent_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§ª Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does 'report' need?\n",
    "deps = graph.get_dependencies('report')\n",
    "print(f\"'report' depends on: {sorted(deps)}\")\n",
    "\n",
    "# What needs 'extract'?\n",
    "dependents = graph.get_dependents('extract')\n",
    "print(f\"'extract' is needed by: {sorted(dependents)}\")\n",
    "\n",
    "# Entry points\n",
    "independent = graph.get_independent_nodes()\n",
    "print(f\"Independent nodes: {independent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(self) -> str:\n",
    "    \"\"\"Generate a text visualization of the graph.\n",
    "    \n",
    "    Returns:\n",
    "        String representation of the graph\n",
    "    \"\"\"\n",
    "    lines = [\"Dependency Graph:\", \"\"]\n",
    "    \n",
    "    # Show execution layers\n",
    "    layers = self.get_execution_layers()\n",
    "    for i, layer in enumerate(layers):\n",
    "        lines.append(f\"Layer {i + 1}:\")\n",
    "        for node_name in sorted(layer):\n",
    "            node = self.nodes[node_name]\n",
    "            deps = (\n",
    "                f\" (depends on: {', '.join(sorted(node.depends_on))})\"\n",
    "                if node.depends_on\n",
    "                else \"\"\n",
    "            )\n",
    "            lines.append(f\"  - {node_name}{deps}\")\n",
    "        lines.append(\"\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Add to DependencyGraph class\n",
    "DependencyGraph.visualize = visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph.visualize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Complete Example - Complex Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realistic data pipeline\n",
    "pipeline_nodes = [\n",
    "    # Sources\n",
    "    NodeConfig('extract_customers', []),\n",
    "    NodeConfig('extract_orders', []),\n",
    "    NodeConfig('extract_products', []),\n",
    "    \n",
    "    # Cleaning\n",
    "    NodeConfig('clean_customers', ['extract_customers']),\n",
    "    NodeConfig('clean_orders', ['extract_orders']),\n",
    "    NodeConfig('clean_products', ['extract_products']),\n",
    "    \n",
    "    # Validation\n",
    "    NodeConfig('validate_customers', ['clean_customers']),\n",
    "    NodeConfig('validate_orders', ['clean_orders']),\n",
    "    \n",
    "    # Enrichment\n",
    "    NodeConfig('enrich_orders', ['validate_orders', 'clean_products']),\n",
    "    \n",
    "    # Aggregation\n",
    "    NodeConfig('customer_metrics', ['validate_customers', 'enrich_orders']),\n",
    "    NodeConfig('product_metrics', ['enrich_orders']),\n",
    "    \n",
    "    # Reporting\n",
    "    NodeConfig('executive_report', ['customer_metrics', 'product_metrics'])\n",
    "]\n",
    "\n",
    "pipeline = DependencyGraph(pipeline_nodes)\n",
    "print(pipeline.visualize())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total nodes: {len(pipeline.nodes)}\")\n",
    "print(f\"Total layers: {len(pipeline.get_execution_layers())}\")\n",
    "print(f\"Max parallelism: {max(len(layer) for layer in pipeline.get_execution_layers())} nodes\")\n",
    "print(f\"\\n'executive_report' requires: {sorted(pipeline.get_dependencies('executive_report'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Key Takeaways\n",
    "\n",
    "1. **Two adjacency lists** enable efficient forward/backward traversal\n",
    "2. **Validation first** catches errors before execution\n",
    "3. **Topological sort** guarantees valid execution order\n",
    "4. **Execution layers** maximize parallelism\n",
    "5. **BFS queries** find transitive dependencies/dependents\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "1. Complete `exercises.ipynb` - build it from scratch\n",
    "2. Read `advanced_graph_algorithms.md` for optimizations\n",
    "3. Move to `06_error_handling` to handle execution failures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
