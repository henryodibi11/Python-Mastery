{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Graph - Complete Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Set, Dict, Optional, Tuple\n",
    "from collections import defaultdict, deque\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class NodeConfig:\n",
    "    name: str\n",
    "    depends_on: List[str]\n",
    "\n",
    "class DependencyError(Exception):\n",
    "    def __init__(self, message: str, cycle: Optional[List[str]] = None):\n",
    "        super().__init__(message)\n",
    "        self.cycle = cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete DependencyGraph Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DependencyGraph:\n",
    "    \"\"\"Complete dependency graph implementation with all features.\"\"\"\n",
    "    \n",
    "    def __init__(self, nodes: List[NodeConfig]):\n",
    "        self.nodes = {node.name: node for node in nodes}\n",
    "        self.adjacency_list: Dict[str, List[str]] = defaultdict(list)\n",
    "        self.reverse_adjacency_list: Dict[str, List[str]] = defaultdict(list)\n",
    "        \n",
    "        self._build_graph()\n",
    "        self._validate_graph()\n",
    "    \n",
    "    def _build_graph(self) -> None:\n",
    "        for node in self.nodes.values():\n",
    "            for dependency in node.depends_on:\n",
    "                self.adjacency_list[dependency].append(node.name)\n",
    "                self.reverse_adjacency_list[node.name].append(dependency)\n",
    "    \n",
    "    def _validate_graph(self) -> None:\n",
    "        self._check_missing_dependencies()\n",
    "        self._check_cycles()\n",
    "    \n",
    "    def _check_missing_dependencies(self) -> None:\n",
    "        missing_deps = []\n",
    "        \n",
    "        for node in self.nodes.values():\n",
    "            for dependency in node.depends_on:\n",
    "                if dependency not in self.nodes:\n",
    "                    missing_deps.append((node.name, dependency))\n",
    "        \n",
    "        if missing_deps:\n",
    "            errors = [\n",
    "                f\"Node '{node}' depends on '{dep}' which doesn't exist\"\n",
    "                for node, dep in missing_deps\n",
    "            ]\n",
    "            raise DependencyError(\"Missing dependencies found:\\n  \" + \"\\n  \".join(errors))\n",
    "    \n",
    "    def _check_cycles(self) -> None:\n",
    "        visited = set()\n",
    "        rec_stack = set()\n",
    "        \n",
    "        def visit(node: str, path: List[str]) -> Optional[List[str]]:\n",
    "            if node in rec_stack:\n",
    "                cycle_start = path.index(node)\n",
    "                return path[cycle_start:] + [node]\n",
    "            \n",
    "            if node in visited:\n",
    "                return None\n",
    "            \n",
    "            visited.add(node)\n",
    "            rec_stack.add(node)\n",
    "            path.append(node)\n",
    "            \n",
    "            for dependent in self.adjacency_list[node]:\n",
    "                cycle = visit(dependent, path[:])\n",
    "                if cycle:\n",
    "                    return cycle\n",
    "            \n",
    "            rec_stack.remove(node)\n",
    "            return None\n",
    "        \n",
    "        for node_name in self.nodes.keys():\n",
    "            if node_name not in visited:\n",
    "                cycle = visit(node_name, [])\n",
    "                if cycle:\n",
    "                    raise DependencyError(\"Circular dependency detected\", cycle=cycle)\n",
    "    \n",
    "    def topological_sort(self) -> List[str]:\n",
    "        in_degree = {name: 0 for name in self.nodes.keys()}\n",
    "        for node in self.nodes.values():\n",
    "            for dependency in node.depends_on:\n",
    "                in_degree[node.name] += 1\n",
    "        \n",
    "        queue = deque([name for name, degree in in_degree.items() if degree == 0])\n",
    "        sorted_nodes = []\n",
    "        \n",
    "        while queue:\n",
    "            node_name = queue.popleft()\n",
    "            sorted_nodes.append(node_name)\n",
    "            \n",
    "            for dependent in self.adjacency_list[node_name]:\n",
    "                in_degree[dependent] -= 1\n",
    "                if in_degree[dependent] == 0:\n",
    "                    queue.append(dependent)\n",
    "        \n",
    "        if len(sorted_nodes) != len(self.nodes):\n",
    "            raise DependencyError(\"Failed to create topological sort (likely cycle)\")\n",
    "        \n",
    "        return sorted_nodes\n",
    "    \n",
    "    def get_execution_layers(self) -> List[List[str]]:\n",
    "        in_degree = {name: len(node.depends_on) for name, node in self.nodes.items()}\n",
    "        \n",
    "        layers = []\n",
    "        remaining = set(self.nodes.keys())\n",
    "        \n",
    "        while remaining:\n",
    "            current_layer = [name for name in remaining if in_degree[name] == 0]\n",
    "            \n",
    "            if not current_layer:\n",
    "                raise DependencyError(\"Cannot create execution layers (likely cycle)\")\n",
    "            \n",
    "            layers.append(current_layer)\n",
    "            \n",
    "            for node_name in current_layer:\n",
    "                remaining.remove(node_name)\n",
    "                for dependent in self.adjacency_list[node_name]:\n",
    "                    if dependent in remaining:\n",
    "                        in_degree[dependent] -= 1\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    def get_dependencies(self, node_name: str) -> Set[str]:\n",
    "        if node_name not in self.nodes:\n",
    "            raise ValueError(f\"Node '{node_name}' not found\")\n",
    "        \n",
    "        dependencies = set()\n",
    "        queue = deque([node_name])\n",
    "        \n",
    "        while queue:\n",
    "            current = queue.popleft()\n",
    "            for dependency in self.reverse_adjacency_list[current]:\n",
    "                if dependency not in dependencies:\n",
    "                    dependencies.add(dependency)\n",
    "                    queue.append(dependency)\n",
    "        \n",
    "        return dependencies\n",
    "    \n",
    "    def get_dependents(self, node_name: str) -> Set[str]:\n",
    "        if node_name not in self.nodes:\n",
    "            raise ValueError(f\"Node '{node_name}' not found\")\n",
    "        \n",
    "        dependents = set()\n",
    "        queue = deque([node_name])\n",
    "        \n",
    "        while queue:\n",
    "            current = queue.popleft()\n",
    "            for dependent in self.adjacency_list[current]:\n",
    "                if dependent not in dependents:\n",
    "                    dependents.add(dependent)\n",
    "                    queue.append(dependent)\n",
    "        \n",
    "        return dependents\n",
    "    \n",
    "    def get_independent_nodes(self) -> List[str]:\n",
    "        return [name for name, node in self.nodes.items() if not node.depends_on]\n",
    "    \n",
    "    def visualize(self) -> str:\n",
    "        lines = [\"Dependency Graph:\", \"\"]\n",
    "        \n",
    "        layers = self.get_execution_layers()\n",
    "        for i, layer in enumerate(layers):\n",
    "            lines.append(f\"Layer {i + 1}:\")\n",
    "            for node_name in sorted(layer):\n",
    "                node = self.nodes[node_name]\n",
    "                deps = (\n",
    "                    f\" (depends on: {', '.join(sorted(node.depends_on))})\"\n",
    "                    if node.depends_on\n",
    "                    else \"\"\n",
    "                )\n",
    "                lines.append(f\"  - {node_name}{deps}\")\n",
    "            lines.append(\"\")\n",
    "        \n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Critical Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critical_path(self) -> Tuple[List[str], int]:\n",
    "    \"\"\"Find the longest path through the graph.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (path, length)\n",
    "    \"\"\"\n",
    "    # Calculate longest path to each node\n",
    "    longest_path = {name: (0, []) for name in self.nodes.keys()}\n",
    "    \n",
    "    # Process nodes in topological order\n",
    "    for node_name in self.topological_sort():\n",
    "        current_length, current_path = longest_path[node_name]\n",
    "        \n",
    "        # Update dependents\n",
    "        for dependent in self.adjacency_list[node_name]:\n",
    "            new_length = current_length + 1\n",
    "            if new_length > longest_path[dependent][0]:\n",
    "                longest_path[dependent] = (new_length, current_path + [node_name])\n",
    "    \n",
    "    # Find node with longest path\n",
    "    max_node = max(longest_path.items(), key=lambda x: x[1][0])\n",
    "    path = max_node[1][1] + [max_node[0]]\n",
    "    length = max_node[1][0]\n",
    "    \n",
    "    return path, length\n",
    "\n",
    "DependencyGraph.get_critical_path = get_critical_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test critical path\n",
    "nodes = [\n",
    "    NodeConfig('A', []),\n",
    "    NodeConfig('B', ['A']),\n",
    "    NodeConfig('C', ['A']),\n",
    "    NodeConfig('D', ['B']),\n",
    "    NodeConfig('E', ['C']),\n",
    "    NodeConfig('F', ['D', 'E'])\n",
    "]\n",
    "\n",
    "graph = DependencyGraph(nodes)\n",
    "path, length = graph.get_critical_path()\n",
    "\n",
    "print(f\"Critical path: {' â†’ '.join(path)}\")\n",
    "print(f\"Length: {length} steps\")\n",
    "print(f\"Minimum execution time: {length + 1} time units (assuming 1 unit per node)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Graph Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(self, other: 'DependencyGraph') -> Dict[str, Set[str]]:\n",
    "    \"\"\"Compare with another graph.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with keys: 'added', 'removed', 'modified'\n",
    "    \"\"\"\n",
    "    old_names = set(self.nodes.keys())\n",
    "    new_names = set(other.nodes.keys())\n",
    "    \n",
    "    added = new_names - old_names\n",
    "    removed = old_names - new_names\n",
    "    common = old_names & new_names\n",
    "    \n",
    "    # Check for modified dependencies\n",
    "    modified = set()\n",
    "    for name in common:\n",
    "        old_deps = set(self.nodes[name].depends_on)\n",
    "        new_deps = set(other.nodes[name].depends_on)\n",
    "        if old_deps != new_deps:\n",
    "            modified.add(name)\n",
    "    \n",
    "    return {\n",
    "        'added': added,\n",
    "        'removed': removed,\n",
    "        'modified': modified\n",
    "    }\n",
    "\n",
    "DependencyGraph.diff = diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test graph diff\n",
    "old_nodes = [\n",
    "    NodeConfig('A', []),\n",
    "    NodeConfig('B', ['A']),\n",
    "    NodeConfig('C', ['A'])\n",
    "]\n",
    "\n",
    "new_nodes = [\n",
    "    NodeConfig('A', []),\n",
    "    NodeConfig('B', ['A', 'D']),  # Modified\n",
    "    NodeConfig('D', [])  # Added\n",
    "    # C removed\n",
    "]\n",
    "\n",
    "old_graph = DependencyGraph(old_nodes)\n",
    "new_graph = DependencyGraph(new_nodes)\n",
    "\n",
    "changes = old_graph.diff(new_graph)\n",
    "print(\"Changes:\")\n",
    "for change_type, nodes in changes.items():\n",
    "    if nodes:\n",
    "        print(f\"  {change_type}: {sorted(nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Minimal Rebuild Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rebuild_set(self, changed_nodes: List[str]) -> Set[str]:\n",
    "    \"\"\"Get all nodes that need re-execution when given nodes change.\n",
    "    \n",
    "    Includes the changed nodes themselves plus all transitive dependents.\n",
    "    \"\"\"\n",
    "    rebuild_set = set(changed_nodes)\n",
    "    \n",
    "    for node in changed_nodes:\n",
    "        if node in self.nodes:\n",
    "            rebuild_set.update(self.get_dependents(node))\n",
    "    \n",
    "    return rebuild_set\n",
    "\n",
    "DependencyGraph.get_rebuild_set = get_rebuild_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test rebuild set\n",
    "pipeline = [\n",
    "    NodeConfig('extract', []),\n",
    "    NodeConfig('clean', ['extract']),\n",
    "    NodeConfig('validate', ['extract']),\n",
    "    NodeConfig('aggregate', ['clean']),\n",
    "    NodeConfig('report', ['aggregate', 'validate'])\n",
    "]\n",
    "\n",
    "graph = DependencyGraph(pipeline)\n",
    "\n",
    "# If 'extract' changes, what needs to rebuild?\n",
    "rebuild = graph.get_rebuild_set(['extract'])\n",
    "print(f\"If 'extract' changes, rebuild: {sorted(rebuild)}\")\n",
    "\n",
    "# If 'clean' changes?\n",
    "rebuild = graph.get_rebuild_set(['clean'])\n",
    "print(f\"If 'clean' changes, rebuild: {sorted(rebuild)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Graph Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(self) -> Dict[str, any]:\n",
    "    \"\"\"Calculate graph metrics.\"\"\"\n",
    "    layers = self.get_execution_layers()\n",
    "    critical_path, critical_length = self.get_critical_path()\n",
    "    \n",
    "    return {\n",
    "        'total_nodes': len(self.nodes),\n",
    "        'total_edges': sum(len(deps) for deps in self.adjacency_list.values()),\n",
    "        'layers': len(layers),\n",
    "        'max_parallelism': max(len(layer) for layer in layers),\n",
    "        'critical_path_length': critical_length,\n",
    "        'independent_nodes': len(self.get_independent_nodes()),\n",
    "        'avg_dependencies': sum(len(n.depends_on) for n in self.nodes.values()) / len(self.nodes)\n",
    "    }\n",
    "\n",
    "DependencyGraph.get_metrics = get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive example\n",
    "complex_pipeline = [\n",
    "    NodeConfig('extract_users', []),\n",
    "    NodeConfig('extract_orders', []),\n",
    "    NodeConfig('extract_products', []),\n",
    "    NodeConfig('clean_users', ['extract_users']),\n",
    "    NodeConfig('clean_orders', ['extract_orders']),\n",
    "    NodeConfig('clean_products', ['extract_products']),\n",
    "    NodeConfig('validate_users', ['clean_users']),\n",
    "    NodeConfig('validate_orders', ['clean_orders']),\n",
    "    NodeConfig('enrich_orders', ['validate_orders', 'clean_products']),\n",
    "    NodeConfig('user_metrics', ['validate_users', 'enrich_orders']),\n",
    "    NodeConfig('product_metrics', ['enrich_orders']),\n",
    "    NodeConfig('dashboard', ['user_metrics', 'product_metrics'])\n",
    "]\n",
    "\n",
    "graph = DependencyGraph(complex_pipeline)\n",
    "\n",
    "print(\"Graph Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in graph.get_metrics().items():\n",
    "    print(f\"{key:25s}: {value}\")\n",
    "\n",
    "print(\"\\n\" + graph.visualize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Key Insights\n",
    "\n",
    "### Algorithm Choices\n",
    "\n",
    "1. **Kahn's vs DFS for topological sort**\n",
    "   - Kahn's: Easier to understand, natural for execution layers\n",
    "   - DFS: More elegant, better for finding all possible orders\n",
    "\n",
    "2. **BFS for dependency queries**\n",
    "   - Level-by-level exploration\n",
    "   - Easy to track visited nodes\n",
    "   - Could use DFS, but BFS more intuitive\n",
    "\n",
    "3. **Two adjacency lists**\n",
    "   - Memory overhead but O(1) access in both directions\n",
    "   - Critical for performance with large graphs\n",
    "\n",
    "### Performance Considerations\n",
    "\n",
    "- All operations: O(N + E) where N = nodes, E = edges\n",
    "- Space: O(N + E) for adjacency lists\n",
    "- Validation happens once in constructor\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "1. **Build Systems**: Make, Bazel, Gradle\n",
    "2. **Data Pipelines**: Airflow, Dagster, Prefect\n",
    "3. **Package Managers**: npm, pip, cargo\n",
    "4. **CI/CD**: GitHub Actions, CircleCI\n",
    "5. **Spreadsheets**: Cell dependency tracking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
