{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story Generation Exercises\n",
    "\n",
    "Practice implementing custom renderers, metadata tracking, and story generation patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Build Custom CSV Renderer\n",
    "\n",
    "Create a `CSVStoryRenderer` that exports pipeline story metadata as CSV format.\n",
    "\n",
    "Requirements:\n",
    "- Export one row per node execution\n",
    "- Include columns: node_name, status, duration, rows_in, rows_out, operation\n",
    "- Include a summary row with pipeline totals\n",
    "- Implement `render()` and `render_to_file()` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odibi.story.metadata import PipelineStoryMetadata, NodeExecutionMetadata\n",
    "import csv\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "class CSVStoryRenderer:\n",
    "    \"\"\"Renders pipeline stories as CSV.\"\"\"\n",
    "    \n",
    "    def render(self, metadata: PipelineStoryMetadata) -> str:\n",
    "        \"\"\"Render story as CSV string.\"\"\"\n",
    "        # TODO: Implement CSV rendering\n",
    "        # Hint: Use csv.DictWriter with StringIO\n",
    "        pass\n",
    "    \n",
    "    def render_to_file(self, metadata: PipelineStoryMetadata, output_path: str) -> str:\n",
    "        \"\"\"Render story and save to CSV file.\"\"\"\n",
    "        # TODO: Implement file writing\n",
    "        pass\n",
    "\n",
    "# Test your implementation\n",
    "test_metadata = PipelineStoryMetadata(\n",
    "    pipeline_name=\"test_pipeline\",\n",
    "    duration=10.5\n",
    ")\n",
    "\n",
    "test_metadata.add_node(NodeExecutionMetadata(\n",
    "    node_name=\"extract\",\n",
    "    operation=\"read_csv\",\n",
    "    status=\"success\",\n",
    "    duration=3.5,\n",
    "    rows_in=0,\n",
    "    rows_out=1000\n",
    "))\n",
    "\n",
    "test_metadata.add_node(NodeExecutionMetadata(\n",
    "    node_name=\"transform\",\n",
    "    operation=\"filter\",\n",
    "    status=\"success\",\n",
    "    duration=2.0,\n",
    "    rows_in=1000,\n",
    "    rows_out=850\n",
    "))\n",
    "\n",
    "renderer = CSVStoryRenderer()\n",
    "csv_output = renderer.render(test_metadata)\n",
    "print(csv_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Add New Metadata Fields\n",
    "\n",
    "Extend `NodeExecutionMetadata` to track memory usage.\n",
    "\n",
    "Requirements:\n",
    "- Add `memory_mb` field (memory used in MB)\n",
    "- Add `peak_memory_mb` field (peak memory during execution)\n",
    "- Add method `calculate_memory_efficiency()` that returns rows_out / memory_mb\n",
    "- Update `to_dict()` to include new fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "@dataclass\n",
    "class EnhancedNodeExecutionMetadata:\n",
    "    \"\"\"Extended metadata with memory tracking.\"\"\"\n",
    "    \n",
    "    node_name: str\n",
    "    operation: str\n",
    "    status: str\n",
    "    duration: float\n",
    "    \n",
    "    # Existing fields\n",
    "    rows_in: Optional[int] = None\n",
    "    rows_out: Optional[int] = None\n",
    "    rows_change: Optional[int] = None\n",
    "    rows_change_pct: Optional[float] = None\n",
    "    \n",
    "    # TODO: Add memory fields\n",
    "    \n",
    "    def calculate_row_change(self):\n",
    "        \"\"\"Calculate row count change metrics.\"\"\"\n",
    "        if self.rows_in is not None and self.rows_out is not None:\n",
    "            self.rows_change = self.rows_out - self.rows_in\n",
    "            if self.rows_in > 0:\n",
    "                self.rows_change_pct = (self.rows_change / self.rows_in) * 100\n",
    "            else:\n",
    "                self.rows_change_pct = 0.0 if self.rows_out == 0 else 100.0\n",
    "    \n",
    "    def calculate_memory_efficiency(self) -> Optional[float]:\n",
    "        \"\"\"Calculate rows processed per MB of memory.\"\"\"\n",
    "        # TODO: Implement memory efficiency calculation\n",
    "        pass\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary.\"\"\"\n",
    "        # TODO: Include all fields including new memory fields\n",
    "        pass\n",
    "\n",
    "# Test your implementation\n",
    "node = EnhancedNodeExecutionMetadata(\n",
    "    node_name=\"memory_test\",\n",
    "    operation=\"transform\",\n",
    "    status=\"success\",\n",
    "    duration=5.0,\n",
    "    rows_out=100000,\n",
    "    # TODO: Add memory values\n",
    ")\n",
    "\n",
    "efficiency = node.calculate_memory_efficiency()\n",
    "print(f\"Memory Efficiency: {efficiency:.2f} rows/MB\")\n",
    "print(f\"\\nMetadata Dict:\")\n",
    "import json\n",
    "print(json.dumps(node.to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Create HTML Theme\n",
    "\n",
    "Create a custom theme for your organization with specific branding.\n",
    "\n",
    "Requirements:\n",
    "- Use your organization's color palette\n",
    "- Include company logo URL\n",
    "- Add custom CSS for:\n",
    "  - Rounded corners on cards\n",
    "  - Gradient background on headers\n",
    "  - Custom hover effects\n",
    "- Include company name and footer text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odibi.story.themes import StoryTheme\n",
    "\n",
    "def create_organization_theme():\n",
    "    \"\"\"Create a branded theme for your organization.\"\"\"\n",
    "    \n",
    "    # TODO: Define your organization's theme\n",
    "    theme = StoryTheme(\n",
    "        name=\"my_org_theme\",\n",
    "        # TODO: Add color scheme\n",
    "        # TODO: Add typography\n",
    "        # TODO: Add branding\n",
    "        # TODO: Add custom CSS\n",
    "    )\n",
    "    \n",
    "    return theme\n",
    "\n",
    "# Test your theme\n",
    "my_theme = create_organization_theme()\n",
    "print(\"Theme CSS:\")\n",
    "print(my_theme.to_css_string())\n",
    "print(\"\\nCSS Variables:\")\n",
    "for var, value in my_theme.to_css_vars().items():\n",
    "    print(f\"  {var}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Implement Story Diff\n",
    "\n",
    "Create a function that compares two pipeline runs and generates a diff report.\n",
    "\n",
    "Requirements:\n",
    "- Compare two `PipelineStoryMetadata` objects\n",
    "- Identify:\n",
    "  - Performance changes (duration differences)\n",
    "  - Data volume changes (row count differences)\n",
    "  - New/removed nodes\n",
    "  - Status changes (success -> failure, etc.)\n",
    "- Generate a markdown report highlighting differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "class StoryDiff:\n",
    "    \"\"\"Compare two pipeline story executions.\"\"\"\n",
    "    \n",
    "    def __init__(self, before: PipelineStoryMetadata, after: PipelineStoryMetadata):\n",
    "        self.before = before\n",
    "        self.after = after\n",
    "    \n",
    "    def compare_performance(self) -> Dict[str, Any]:\n",
    "        \"\"\"Compare overall performance metrics.\"\"\"\n",
    "        # TODO: Compare durations, success rates, etc.\n",
    "        pass\n",
    "    \n",
    "    def compare_nodes(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Identify node changes.\"\"\"\n",
    "        # TODO: Find added, removed, and changed nodes\n",
    "        pass\n",
    "    \n",
    "    def compare_data_volume(self) -> Dict[str, Any]:\n",
    "        \"\"\"Compare data processing volumes.\"\"\"\n",
    "        # TODO: Compare row counts across pipeline\n",
    "        pass\n",
    "    \n",
    "    def generate_report(self) -> str:\n",
    "        \"\"\"Generate markdown diff report.\"\"\"\n",
    "        # TODO: Create comprehensive diff report\n",
    "        pass\n",
    "\n",
    "# Test with two different runs\n",
    "run1 = PipelineStoryMetadata(\n",
    "    pipeline_name=\"test\",\n",
    "    duration=10.0,\n",
    "    started_at=\"2024-01-15T10:00:00\"\n",
    ")\n",
    "run1.add_node(NodeExecutionMetadata(\n",
    "    node_name=\"extract\",\n",
    "    operation=\"read\",\n",
    "    status=\"success\",\n",
    "    duration=3.0,\n",
    "    rows_out=1000\n",
    "))\n",
    "run1.add_node(NodeExecutionMetadata(\n",
    "    node_name=\"transform\",\n",
    "    operation=\"filter\",\n",
    "    status=\"success\",\n",
    "    duration=7.0,\n",
    "    rows_in=1000,\n",
    "    rows_out=900\n",
    "))\n",
    "\n",
    "run2 = PipelineStoryMetadata(\n",
    "    pipeline_name=\"test\",\n",
    "    duration=8.0,\n",
    "    started_at=\"2024-01-15T11:00:00\"\n",
    ")\n",
    "run2.add_node(NodeExecutionMetadata(\n",
    "    node_name=\"extract\",\n",
    "    operation=\"read\",\n",
    "    status=\"success\",\n",
    "    duration=2.5,\n",
    "    rows_out=1000\n",
    "))\n",
    "run2.add_node(NodeExecutionMetadata(\n",
    "    node_name=\"transform\",\n",
    "    operation=\"filter\",\n",
    "    status=\"success\",\n",
    "    duration=5.5,\n",
    "    rows_in=1000,\n",
    "    rows_out=900\n",
    "))\n",
    "\n",
    "diff = StoryDiff(run1, run2)\n",
    "report = diff.generate_report()\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Story Analytics Dashboard\n",
    "\n",
    "Create a function that analyzes multiple story files and generates summary statistics.\n",
    "\n",
    "Requirements:\n",
    "- Read multiple JSON story files from a directory\n",
    "- Calculate aggregate metrics:\n",
    "  - Average pipeline duration\n",
    "  - Most common failure points\n",
    "  - Slowest nodes across all runs\n",
    "  - Total data processed\n",
    "- Generate a summary report with trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "class StoryAnalyzer:\n",
    "    \"\"\"Analyze multiple pipeline story executions.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stories: List[Dict] = []\n",
    "    \n",
    "    def load_from_directory(self, directory: str):\n",
    "        \"\"\"Load all JSON story files from directory.\"\"\"\n",
    "        # TODO: Read all .json files and parse them\n",
    "        pass\n",
    "    \n",
    "    def add_story(self, story_dict: Dict):\n",
    "        \"\"\"Add a story to the analysis.\"\"\"\n",
    "        self.stories.append(story_dict)\n",
    "    \n",
    "    def get_average_duration(self) -> float:\n",
    "        \"\"\"Calculate average pipeline duration.\"\"\"\n",
    "        # TODO: Calculate average\n",
    "        pass\n",
    "    \n",
    "    def get_failure_hotspots(self) -> List[Tuple[str, int]]:\n",
    "        \"\"\"Find nodes that fail most frequently.\"\"\"\n",
    "        # TODO: Count failures by node name\n",
    "        pass\n",
    "    \n",
    "    def get_slowest_nodes(self, top_n: int = 5) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Find slowest nodes across all runs.\"\"\"\n",
    "        # TODO: Aggregate node durations\n",
    "        pass\n",
    "    \n",
    "    def get_total_data_processed(self) -> int:\n",
    "        \"\"\"Calculate total rows processed across all runs.\"\"\"\n",
    "        # TODO: Sum all rows_processed\n",
    "        pass\n",
    "    \n",
    "    def generate_dashboard(self) -> str:\n",
    "        \"\"\"Generate markdown analytics dashboard.\"\"\"\n",
    "        # TODO: Create comprehensive analytics report\n",
    "        pass\n",
    "\n",
    "# Test with sample data\n",
    "analyzer = StoryAnalyzer()\n",
    "\n",
    "# Add sample stories\n",
    "for i in range(3):\n",
    "    sample_story = {\n",
    "        \"pipeline_name\": \"test\",\n",
    "        \"duration\": 10.0 + i,\n",
    "        \"total_rows_processed\": 5000,\n",
    "        \"nodes\": [\n",
    "            {\"node_name\": \"extract\", \"status\": \"success\", \"duration\": 3.0},\n",
    "            {\"node_name\": \"transform\", \"status\": \"failed\" if i == 1 else \"success\", \"duration\": 7.0}\n",
    "        ]\n",
    "    }\n",
    "    analyzer.add_story(sample_story)\n",
    "\n",
    "dashboard = analyzer.generate_dashboard()\n",
    "print(dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Exercise: Interactive Story Viewer\n",
    "\n",
    "Create a simple interactive story viewer using widgets (if in Jupyter).\n",
    "\n",
    "Requirements:\n",
    "- Dropdown to select from multiple story files\n",
    "- Display story metadata in formatted output\n",
    "- Show node-by-node breakdown\n",
    "- Include expandable sections for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Requires ipywidgets\n",
    "try:\n",
    "    from ipywidgets import interact, Dropdown, Output\n",
    "    from IPython.display import display, HTML, Markdown\n",
    "    \n",
    "    def create_story_viewer(stories: List[PipelineStoryMetadata]):\n",
    "        \"\"\"Create interactive story viewer.\"\"\"\n",
    "        # TODO: Implement interactive viewer\n",
    "        pass\n",
    "    \n",
    "    # Test implementation\n",
    "    print(\"Interactive viewer implementation here\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Interactive viewer requires: pip install ipywidgets\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
