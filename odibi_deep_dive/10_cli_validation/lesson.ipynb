{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI Architecture with Click\n",
    "\n",
    "**Module 10: Building Professional CLIs with Click**\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand CLI architecture patterns\n",
    "- Build commands with Click\n",
    "- Implement config validation workflows\n",
    "- Create rich error messages\n",
    "- Handle exceptions gracefully\n",
    "- Test CLI commands\n",
    "\n",
    "---\n",
    "\n",
    "## Why Click?\n",
    "\n",
    "**Problems with argparse:**\n",
    "- Verbose boilerplate\n",
    "- Manual type conversion\n",
    "- Limited composability\n",
    "- Poor testing support\n",
    "\n",
    "**Click advantages:**\n",
    "- Decorator-based API\n",
    "- Automatic help generation\n",
    "- Nested command groups\n",
    "- Built-in testing utilities\n",
    "- Type validation\n",
    "- File path handling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Click Basics\n",
    "\n",
    "### Simple Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "\n",
    "@click.command()\n",
    "@click.argument('name')\n",
    "@click.option('--greeting', default='Hello', help='Greeting to use')\n",
    "def greet(name, greeting):\n",
    "    \"\"\"Simple greeting command.\"\"\"\n",
    "    click.echo(f\"{greeting}, {name}!\")\n",
    "\n",
    "# Simulate CLI call\n",
    "from click.testing import CliRunner\n",
    "runner = CliRunner()\n",
    "\n",
    "result = runner.invoke(greet, ['World'])\n",
    "print(result.output)\n",
    "\n",
    "result = runner.invoke(greet, ['Alice', '--greeting', 'Hi'])\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments vs Options\n",
    "\n",
    "**Arguments:**\n",
    "- Required (unless optional=True)\n",
    "- Positional\n",
    "- No -- prefix\n",
    "\n",
    "**Options:**\n",
    "- Optional by default\n",
    "- Named with -- prefix\n",
    "- Can have short forms (-v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@click.command()\n",
    "@click.argument('config_file', type=click.Path(exists=True))\n",
    "@click.option('--env', type=click.Choice(['dev', 'prod']), default='dev')\n",
    "@click.option('--verbose', '-v', is_flag=True, help='Enable verbose output')\n",
    "@click.option('--retries', type=int, default=3, help='Number of retries')\n",
    "def process(config_file, env, verbose, retries):\n",
    "    \"\"\"Process config file.\"\"\"\n",
    "    if verbose:\n",
    "        click.echo(f\"Loading {config_file}...\")\n",
    "    click.echo(f\"Environment: {env}\")\n",
    "    click.echo(f\"Max retries: {retries}\")\n",
    "\n",
    "# Test\n",
    "import tempfile\n",
    "with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:\n",
    "    f.write(\"test: data\")\n",
    "    temp_path = f.name\n",
    "\n",
    "runner = CliRunner()\n",
    "result = runner.invoke(process, [temp_path, '--env', 'prod', '-v', '--retries', '5'])\n",
    "print(result.output)\n",
    "\n",
    "import os\n",
    "os.unlink(temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Command Groups\n",
    "\n",
    "### Building Multi-Command CLIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@click.group()\n",
    "def odibi():\n",
    "    \"\"\"Odibi Data Pipeline Framework.\"\"\"\n",
    "    pass\n",
    "\n",
    "@odibi.command()\n",
    "@click.argument('config')\n",
    "def validate(config):\n",
    "    \"\"\"Validate configuration file.\"\"\"\n",
    "    click.echo(f\"Validating {config}...\")\n",
    "    click.secho(\"‚úì Config is valid\", fg='green')\n",
    "\n",
    "@odibi.command()\n",
    "@click.argument('config')\n",
    "@click.option('--env', default='development')\n",
    "def run(config, env):\n",
    "    \"\"\"Execute pipeline.\"\"\"\n",
    "    click.echo(f\"Running {config} in {env} mode...\")\n",
    "    click.secho(\"‚úì Pipeline completed\", fg='green')\n",
    "\n",
    "# Test\n",
    "runner = CliRunner()\n",
    "\n",
    "# Show help\n",
    "result = runner.invoke(odibi, ['--help'])\n",
    "print(result.output)\n",
    "print()\n",
    "\n",
    "# Run commands\n",
    "result = runner.invoke(odibi, ['validate', 'config.yaml'])\n",
    "print(result.output)\n",
    "\n",
    "result = runner.invoke(odibi, ['run', 'config.yaml', '--env', 'production'])\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Odibi's CLI Architecture\n",
    "\n",
    "### Current Implementation (argparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From odibi/cli/main.py\n",
    "import argparse\n",
    "\n",
    "def create_parser():\n",
    "    \"\"\"Odibi's current argparse-based CLI.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Odibi Data Pipeline Framework\",\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "        epilog=\"\"\"\n",
    "Examples:\n",
    "  odibi run config.yaml                    Run a pipeline\n",
    "  odibi validate config.yaml               Validate configuration\n",
    "  odibi story generate config.yaml         Generate documentation\n",
    "        \"\"\",\n",
    "    )\n",
    "    subparsers = parser.add_subparsers(dest=\"command\", help=\"Available commands\")\n",
    "\n",
    "    # Run command\n",
    "    run_parser = subparsers.add_parser(\"run\", help=\"Execute pipeline\")\n",
    "    run_parser.add_argument(\"config\", help=\"Path to YAML config file\")\n",
    "    run_parser.add_argument(\n",
    "        \"--env\", default=\"development\", help=\"Environment (development/production)\"\n",
    "    )\n",
    "\n",
    "    # Validate command\n",
    "    validate_parser = subparsers.add_parser(\"validate\", help=\"Validate config\")\n",
    "    validate_parser.add_argument(\"config\", help=\"Path to YAML config file\")\n",
    "\n",
    "    return parser\n",
    "\n",
    "parser = create_parser()\n",
    "args = parser.parse_args(['validate', 'config.yaml'])\n",
    "print(f\"Command: {args.command}\")\n",
    "print(f\"Config: {args.config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Command Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From odibi/cli/validate.py\n",
    "import yaml\n",
    "from typing import Dict, Any\n",
    "\n",
    "def validate_config_simple(config_path: str) -> int:\n",
    "    \"\"\"Simple validation - load YAML and check structure.\"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as f:\n",
    "            config_data = yaml.safe_load(f)\n",
    "        \n",
    "        # Basic validation\n",
    "        if not isinstance(config_data, dict):\n",
    "            raise ValueError(\"Config must be a dictionary\")\n",
    "        \n",
    "        if 'connections' not in config_data:\n",
    "            raise ValueError(\"Missing 'connections' section\")\n",
    "        \n",
    "        if 'pipelines' not in config_data:\n",
    "            raise ValueError(\"Missing 'pipelines' section\")\n",
    "        \n",
    "        print(\"‚úì Config is valid\")\n",
    "        return 0\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚úó Config file not found: {config_path}\")\n",
    "        return 1\n",
    "    \n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"‚úó YAML parse error: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Validation failed: {e}\")\n",
    "        return 1\n",
    "\n",
    "# Create test config\n",
    "test_config = \"\"\"\n",
    "connections:\n",
    "  db:\n",
    "    type: databricks\n",
    "    catalog: main\n",
    "\n",
    "pipelines:\n",
    "  sales_etl:\n",
    "    steps:\n",
    "      - extract:\n",
    "          sql: \"SELECT * FROM sales\"\n",
    "\"\"\"\n",
    "\n",
    "with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:\n",
    "    f.write(test_config)\n",
    "    config_path = f.name\n",
    "\n",
    "# Test validation\n",
    "result = validate_config_simple(config_path)\n",
    "print(f\"Exit code: {result}\")\n",
    "\n",
    "os.unlink(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Custom Exceptions\n",
    "\n",
    "### Exception Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From odibi/exceptions.py\n",
    "from typing import Optional, List\n",
    "\n",
    "class OdibiException(Exception):\n",
    "    \"\"\"Base exception for all ODIBI errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "class ConfigValidationError(OdibiException):\n",
    "    \"\"\"Configuration validation failed.\"\"\"\n",
    "\n",
    "    def __init__(self, message: str, file: Optional[str] = None, line: Optional[int] = None):\n",
    "        self.message = message\n",
    "        self.file = file\n",
    "        self.line = line\n",
    "        super().__init__(self._format_error())\n",
    "\n",
    "    def _format_error(self) -> str:\n",
    "        \"\"\"Format error message with location info.\"\"\"\n",
    "        parts = [\"Configuration validation error\"]\n",
    "        if self.file:\n",
    "            parts.append(f\"\\n  File: {self.file}\")\n",
    "        if self.line:\n",
    "            parts.append(f\"\\n  Line: {self.line}\")\n",
    "        parts.append(f\"\\n  Error: {self.message}\")\n",
    "        return \"\".join(parts)\n",
    "\n",
    "# Test\n",
    "try:\n",
    "    raise ConfigValidationError(\n",
    "        message=\"Missing required field 'name'\",\n",
    "        file=\"config.yaml\",\n",
    "        line=15\n",
    "    )\n",
    "except ConfigValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rich Connection Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectionError(OdibiException):\n",
    "    \"\"\"Connection failed or invalid.\"\"\"\n",
    "\n",
    "    def __init__(self, connection_name: str, reason: str, suggestions: Optional[List[str]] = None):\n",
    "        self.connection_name = connection_name\n",
    "        self.reason = reason\n",
    "        self.suggestions = suggestions or []\n",
    "        super().__init__(self._format_error())\n",
    "\n",
    "    def _format_error(self) -> str:\n",
    "        \"\"\"Format connection error with suggestions.\"\"\"\n",
    "        parts = [\n",
    "            f\"‚úó Connection validation failed: {self.connection_name}\",\n",
    "            f\"\\n  Reason: {self.reason}\",\n",
    "        ]\n",
    "\n",
    "        if self.suggestions:\n",
    "            parts.append(\"\\n\\n  Suggestions:\")\n",
    "            for i, suggestion in enumerate(self.suggestions, 1):\n",
    "                parts.append(f\"\\n    {i}. {suggestion}\")\n",
    "\n",
    "        return \"\".join(parts)\n",
    "\n",
    "# Test\n",
    "try:\n",
    "    raise ConnectionError(\n",
    "        connection_name=\"prod_db\",\n",
    "        reason=\"Catalog 'analytics' not found\",\n",
    "        suggestions=[\n",
    "            \"Check catalog name spelling\",\n",
    "            \"Verify catalog access permissions\",\n",
    "            \"Use 'odibi list catalogs' to see available catalogs\"\n",
    "        ]\n",
    "    )\n",
    "except ConnectionError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Context for Better Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ExecutionContext:\n",
    "    \"\"\"Runtime context for error reporting.\"\"\"\n",
    "    node_name: str\n",
    "    config_file: Optional[str] = None\n",
    "    config_line: Optional[int] = None\n",
    "    step_index: Optional[int] = None\n",
    "    total_steps: Optional[int] = None\n",
    "    input_schema: Optional[List[str]] = None\n",
    "    input_shape: Optional[tuple] = None\n",
    "    previous_steps: Optional[List[str]] = None\n",
    "\n",
    "class NodeExecutionError(OdibiException):\n",
    "    \"\"\"Node execution failed.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        message: str,\n",
    "        context: ExecutionContext,\n",
    "        original_error: Optional[Exception] = None,\n",
    "        suggestions: Optional[List[str]] = None,\n",
    "    ):\n",
    "        self.message = message\n",
    "        self.context = context\n",
    "        self.original_error = original_error\n",
    "        self.suggestions = suggestions or []\n",
    "        super().__init__(self._format_error())\n",
    "\n",
    "    def _format_error(self) -> str:\n",
    "        \"\"\"Generate rich error message with context.\"\"\"\n",
    "        parts = [f\"‚úó Node execution failed: {self.context.node_name}\"]\n",
    "\n",
    "        # Location info\n",
    "        if self.context.config_file:\n",
    "            parts.append(f\"\\n  Location: {self.context.config_file}\")\n",
    "            if self.context.config_line:\n",
    "                parts.append(f\":{self.context.config_line}\")\n",
    "\n",
    "        # Step info\n",
    "        if self.context.step_index is not None and self.context.total_steps:\n",
    "            parts.append(f\"\\n  Step: {self.context.step_index + 1} of {self.context.total_steps}\")\n",
    "\n",
    "        # Error message\n",
    "        parts.append(f\"\\n\\n  Error: {self.message}\")\n",
    "\n",
    "        # Context information\n",
    "        if self.context.input_schema:\n",
    "            parts.append(f\"\\n\\n  Available columns: {self.context.input_schema}\")\n",
    "\n",
    "        if self.context.previous_steps:\n",
    "            parts.append(\"\\n\\n  Previous steps:\")\n",
    "            for step in self.context.previous_steps:\n",
    "                parts.append(f\"\\n    ‚úì {step}\")\n",
    "\n",
    "        # Suggestions\n",
    "        if self.suggestions:\n",
    "            parts.append(\"\\n\\n  Suggestions:\")\n",
    "            for i, suggestion in enumerate(self.suggestions, 1):\n",
    "                parts.append(f\"\\n    {i}. {suggestion}\")\n",
    "\n",
    "        return \"\".join(parts)\n",
    "\n",
    "# Test\n",
    "try:\n",
    "    ctx = ExecutionContext(\n",
    "        node_name=\"calculate_margin\",\n",
    "        config_file=\"sales_pipeline.yaml\",\n",
    "        config_line=42,\n",
    "        step_index=2,\n",
    "        total_steps=5,\n",
    "        input_schema=['order_id', 'amount', 'discount'],\n",
    "        previous_steps=['extract_orders', 'clean_data']\n",
    "    )\n",
    "    \n",
    "    raise NodeExecutionError(\n",
    "        message=\"Column 'revenue' not found\",\n",
    "        context=ctx,\n",
    "        suggestions=[\n",
    "            \"Check column name spelling\",\n",
    "            \"Verify upstream transformation produces 'revenue'\",\n",
    "            \"Add revenue calculation in previous step\"\n",
    "        ]\n",
    "    )\n",
    "except NodeExecutionError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Validation Workflow\n",
    "\n",
    "### Explanation Linter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From odibi/validation/explanation_linter.py\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class LintIssue:\n",
    "    \"\"\"A linting issue found in an explanation.\"\"\"\n",
    "    severity: str  # \"error\", \"warning\", \"info\"\n",
    "    message: str\n",
    "    rule: str\n",
    "\n",
    "    def __str__(self):\n",
    "        symbol = {\"error\": \"‚ùå\", \"warning\": \"‚ö†Ô∏è\", \"info\": \"‚ÑπÔ∏è\"}[self.severity]\n",
    "        return f\"{symbol} {self.message} [{self.rule}]\"\n",
    "\n",
    "\n",
    "class ExplanationLinter:\n",
    "    \"\"\"\n",
    "    Lints explanation text for quality issues.\n",
    "\n",
    "    Checks:\n",
    "    - Minimum length\n",
    "    - Required sections (Purpose, Details, Result)\n",
    "    - Generic/lazy phrases\n",
    "    - TODO placeholders\n",
    "    - Formula formatting\n",
    "    \"\"\"\n",
    "\n",
    "    REQUIRED_SECTIONS = [\"Purpose\", \"Details\", \"Result\"]\n",
    "    LAZY_PHRASES = [\n",
    "        \"calculates stuff\",\n",
    "        \"does things\",\n",
    "        \"processes data\",\n",
    "        \"handles records\",\n",
    "        \"TODO\",\n",
    "        \"[placeholder]\",\n",
    "        \"TBD\",\n",
    "    ]\n",
    "    MIN_LENGTH = 50\n",
    "\n",
    "    def __init__(self):\n",
    "        self.issues: List[LintIssue] = []\n",
    "\n",
    "    def lint(self, explanation: str, operation_name: str = \"unknown\") -> List[LintIssue]:\n",
    "        \"\"\"Lint an explanation and return issues.\"\"\"\n",
    "        self.issues = []\n",
    "\n",
    "        if not explanation or not explanation.strip():\n",
    "            self.issues.append(\n",
    "                LintIssue(\n",
    "                    severity=\"error\",\n",
    "                    message=f\"Explanation for '{operation_name}' is empty\",\n",
    "                    rule=\"E001\",\n",
    "                )\n",
    "            )\n",
    "            return self.issues\n",
    "\n",
    "        # Check length\n",
    "        if len(explanation.strip()) < self.MIN_LENGTH:\n",
    "            self.issues.append(\n",
    "                LintIssue(\n",
    "                    severity=\"error\",\n",
    "                    message=f\"Explanation for '{operation_name}' too short ({len(explanation.strip())} chars)\",\n",
    "                    rule=\"E002\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Check required sections\n",
    "        for section in self.REQUIRED_SECTIONS:\n",
    "            pattern = f\"\\\\*\\\\*{section}:?\\\\*\\\\*\"\n",
    "            if not re.search(pattern, explanation, re.IGNORECASE):\n",
    "                self.issues.append(\n",
    "                    LintIssue(\n",
    "                        severity=\"error\",\n",
    "                        message=f\"Explanation for '{operation_name}' missing section: {section}\",\n",
    "                        rule=\"E003\",\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # Check for lazy phrases\n",
    "        text_lower = explanation.lower()\n",
    "        for phrase in self.LAZY_PHRASES:\n",
    "            if phrase.lower() in text_lower:\n",
    "                self.issues.append(\n",
    "                    LintIssue(\n",
    "                        severity=\"error\",\n",
    "                        message=f\"Explanation for '{operation_name}' contains generic phrase: '{phrase}'\",\n",
    "                        rule=\"E004\",\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return self.issues\n",
    "\n",
    "    def has_errors(self) -> bool:\n",
    "        \"\"\"Check if any errors were found.\"\"\"\n",
    "        return any(issue.severity == \"error\" for issue in self.issues)\n",
    "\n",
    "# Test\n",
    "linter = ExplanationLinter()\n",
    "\n",
    "# Bad explanation\n",
    "bad_explanation = \"This step processes data.\"\n",
    "issues = linter.lint(bad_explanation, \"extract\")\n",
    "print(\"Bad explanation issues:\")\n",
    "for issue in issues:\n",
    "    print(f\"  {issue}\")\n",
    "print()\n",
    "\n",
    "# Good explanation\n",
    "good_explanation = \"\"\"\n",
    "**Purpose:** Calculate profit margin for each sale\n",
    "**Details:** Uses the formula (revenue - cost) / revenue * 100\n",
    "**Result:** Adds 'margin_pct' column with percentage values\n",
    "\"\"\"\n",
    "issues = linter.lint(good_explanation, \"calculate_margin\")\n",
    "if not issues:\n",
    "    print(\"‚úÖ Good explanation - no issues\")\n",
    "else:\n",
    "    for issue in issues:\n",
    "        print(f\"  {issue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Click with Rich Output\n",
    "\n",
    "### Colored Output and Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "import time\n",
    "\n",
    "@click.command()\n",
    "@click.argument('config', type=click.Path(exists=True))\n",
    "@click.option('--verbose', '-v', is_flag=True)\n",
    "def validate_with_progress(config, verbose):\n",
    "    \"\"\"Validate config with progress indication.\"\"\"\n",
    "    \n",
    "    checks = [\n",
    "        (\"YAML syntax\", 0.3),\n",
    "        (\"Schema validation\", 0.5),\n",
    "        (\"Connection validation\", 0.7),\n",
    "        (\"Pipeline structure\", 0.4),\n",
    "        (\"Explanation quality\", 0.6),\n",
    "    ]\n",
    "    \n",
    "    click.echo(f\"\\nValidating {config}...\\n\")\n",
    "    \n",
    "    with click.progressbar(\n",
    "        checks,\n",
    "        label='Validation',\n",
    "        show_eta=False,\n",
    "        item_show_func=lambda x: x[0] if x else ''\n",
    "    ) as bar:\n",
    "        for check_name, duration in bar:\n",
    "            if verbose:\n",
    "                click.echo(f\"  Checking {check_name}...\")\n",
    "            time.sleep(duration)\n",
    "    \n",
    "    click.echo()\n",
    "    click.secho(\"‚úì All validation checks passed\", fg='green', bold=True)\n",
    "    click.echo()\n",
    "    click.secho(\"Summary:\", fg='cyan')\n",
    "    click.echo(f\"  ‚Ä¢ {len(checks)} checks completed\")\n",
    "    click.echo(f\"  ‚Ä¢ 0 errors, 0 warnings\")\n",
    "\n",
    "# Note: Progress bar won't show in notebook, but works in terminal\n",
    "# Simulating output:\n",
    "print(\"\\nValidating config.yaml...\\n\")\n",
    "print(\"Validation  [####################################]  100%  Explanation quality\")\n",
    "print()\n",
    "print(\"\\033[92m‚úì All validation checks passed\\033[0m\")\n",
    "print()\n",
    "print(\"\\033[96mSummary:\\033[0m\")\n",
    "print(\"  ‚Ä¢ 5 checks completed\")\n",
    "print(\"  ‚Ä¢ 0 errors, 0 warnings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Testing CLI Commands\n",
    "\n",
    "### Click's Test Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from click.testing import CliRunner\n",
    "import pytest\n",
    "\n",
    "@click.command()\n",
    "@click.argument('name')\n",
    "@click.option('--uppercase', is_flag=True)\n",
    "def greet(name, uppercase):\n",
    "    \"\"\"Greet someone.\"\"\"\n",
    "    greeting = f\"Hello, {name}!\"\n",
    "    if uppercase:\n",
    "        greeting = greeting.upper()\n",
    "    click.echo(greeting)\n",
    "\n",
    "# Test suite\n",
    "def test_greet_basic():\n",
    "    runner = CliRunner()\n",
    "    result = runner.invoke(greet, ['Alice'])\n",
    "    assert result.exit_code == 0\n",
    "    assert result.output == \"Hello, Alice!\\n\"\n",
    "\n",
    "def test_greet_uppercase():\n",
    "    runner = CliRunner()\n",
    "    result = runner.invoke(greet, ['Bob', '--uppercase'])\n",
    "    assert result.exit_code == 0\n",
    "    assert result.output == \"HELLO, BOB!\\n\"\n",
    "\n",
    "def test_greet_missing_arg():\n",
    "    runner = CliRunner()\n",
    "    result = runner.invoke(greet, [])\n",
    "    assert result.exit_code != 0\n",
    "    assert \"Error\" in result.output\n",
    "\n",
    "# Run tests\n",
    "test_greet_basic()\n",
    "print(\"‚úì test_greet_basic passed\")\n",
    "\n",
    "test_greet_uppercase()\n",
    "print(\"‚úì test_greet_uppercase passed\")\n",
    "\n",
    "test_greet_missing_arg()\n",
    "print(\"‚úì test_greet_missing_arg passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with Temp Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@click.command()\n",
    "@click.argument('config', type=click.Path(exists=True))\n",
    "def validate_config(config):\n",
    "    \"\"\"Validate YAML config.\"\"\"\n",
    "    import yaml\n",
    "    \n",
    "    try:\n",
    "        with open(config) as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        \n",
    "        # Validate structure\n",
    "        if 'pipelines' not in data:\n",
    "            raise ValueError(\"Missing 'pipelines' key\")\n",
    "        \n",
    "        click.secho(\"‚úì Config is valid\", fg='green')\n",
    "        \n",
    "    except Exception as e:\n",
    "        click.secho(f\"‚úó Validation failed: {e}\", fg='red', err=True)\n",
    "        raise click.Abort()\n",
    "\n",
    "def test_validate_config_valid():\n",
    "    runner = CliRunner()\n",
    "    \n",
    "    with runner.isolated_filesystem():\n",
    "        # Create valid config\n",
    "        with open('config.yaml', 'w') as f:\n",
    "            f.write('pipelines:\\n  - name: test\\n')\n",
    "        \n",
    "        result = runner.invoke(validate_config, ['config.yaml'])\n",
    "        assert result.exit_code == 0\n",
    "        assert \"‚úì\" in result.output\n",
    "\n",
    "def test_validate_config_invalid():\n",
    "    runner = CliRunner()\n",
    "    \n",
    "    with runner.isolated_filesystem():\n",
    "        # Create invalid config\n",
    "        with open('config.yaml', 'w') as f:\n",
    "            f.write('connections:\\n  - name: db\\n')\n",
    "        \n",
    "        result = runner.invoke(validate_config, ['config.yaml'])\n",
    "        assert result.exit_code != 0\n",
    "        assert \"Missing 'pipelines'\" in result.output\n",
    "\n",
    "# Run tests\n",
    "test_validate_config_valid()\n",
    "print(\"‚úì test_validate_config_valid passed\")\n",
    "\n",
    "test_validate_config_invalid()\n",
    "print(\"‚úì test_validate_config_invalid passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Complete Validation Command\n",
    "\n",
    "### Production-Ready Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@click.command()\n",
    "@click.argument('config', type=click.Path(exists=True))\n",
    "@click.option('--strict', is_flag=True, help='Fail on warnings')\n",
    "@click.option('--verbose', '-v', is_flag=True, help='Show detailed output')\n",
    "def validate(\n",
    "    config: str,\n",
    "    strict: bool,\n",
    "    verbose: bool\n",
    ") -> None:\n",
    "    \"\"\"Validate Odibi configuration file.\n",
    "    \n",
    "    Performs comprehensive validation:\n",
    "    - YAML syntax\n",
    "    - Schema structure\n",
    "    - Connection configs\n",
    "    - Pipeline definitions\n",
    "    - Explanation quality\n",
    "    \"\"\"\n",
    "    import yaml\n",
    "    \n",
    "    errors = []\n",
    "    warnings = []\n",
    "    \n",
    "    try:\n",
    "        # 1. Load YAML\n",
    "        if verbose:\n",
    "            click.echo(\"üìÑ Loading config file...\")\n",
    "        \n",
    "        with open(config) as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        \n",
    "        # 2. Validate structure\n",
    "        if verbose:\n",
    "            click.echo(\"üîç Validating structure...\")\n",
    "        \n",
    "        if not isinstance(data, dict):\n",
    "            errors.append(\"Config must be a dictionary\")\n",
    "        \n",
    "        if 'connections' not in data:\n",
    "            errors.append(\"Missing 'connections' section\")\n",
    "        \n",
    "        if 'pipelines' not in data:\n",
    "            errors.append(\"Missing 'pipelines' section\")\n",
    "        \n",
    "        # 3. Validate connections\n",
    "        if verbose:\n",
    "            click.echo(\"üîå Validating connections...\")\n",
    "        \n",
    "        if 'connections' in data:\n",
    "            for name, conn in data['connections'].items():\n",
    "                if 'type' not in conn:\n",
    "                    errors.append(f\"Connection '{name}' missing 'type'\")\n",
    "        \n",
    "        # 4. Validate pipelines\n",
    "        if verbose:\n",
    "            click.echo(\"‚öôÔ∏è  Validating pipelines...\")\n",
    "        \n",
    "        if 'pipelines' in data:\n",
    "            for name, pipeline in data['pipelines'].items():\n",
    "                if 'steps' not in pipeline:\n",
    "                    errors.append(f\"Pipeline '{name}' missing 'steps'\")\n",
    "                else:\n",
    "                    # Check explanations\n",
    "                    for i, step in enumerate(pipeline['steps']):\n",
    "                        step_name = f\"{name}.step{i}\"\n",
    "                        \n",
    "                        # Get explanation from step\n",
    "                        explanation = None\n",
    "                        for key, value in step.items():\n",
    "                            if isinstance(value, dict) and 'explanation' in value:\n",
    "                                explanation = value['explanation']\n",
    "                        \n",
    "                        if not explanation:\n",
    "                            warnings.append(f\"Step '{step_name}' missing explanation\")\n",
    "                        else:\n",
    "                            # Lint explanation\n",
    "                            linter = ExplanationLinter()\n",
    "                            issues = linter.lint(explanation, step_name)\n",
    "                            \n",
    "                            for issue in issues:\n",
    "                                if issue.severity == 'error':\n",
    "                                    errors.append(f\"{step_name}: {issue.message}\")\n",
    "                                elif issue.severity == 'warning':\n",
    "                                    warnings.append(f\"{step_name}: {issue.message}\")\n",
    "        \n",
    "        # Report results\n",
    "        click.echo()\n",
    "        \n",
    "        if errors:\n",
    "            click.secho(\"‚ùå Validation failed\", fg='red', bold=True)\n",
    "            click.echo()\n",
    "            click.secho(f\"Errors ({len(errors)}):\", fg='red')\n",
    "            for error in errors:\n",
    "                click.echo(f\"  ‚Ä¢ {error}\")\n",
    "            click.echo()\n",
    "        \n",
    "        if warnings:\n",
    "            click.secho(f\"Warnings ({len(warnings)}):\", fg='yellow')\n",
    "            for warning in warnings:\n",
    "                click.echo(f\"  ‚Ä¢ {warning}\")\n",
    "            click.echo()\n",
    "        \n",
    "        if not errors and not warnings:\n",
    "            click.secho(\"‚úÖ Configuration is valid\", fg='green', bold=True)\n",
    "        elif not errors:\n",
    "            click.secho(\"‚úÖ Configuration is valid (with warnings)\", fg='green', bold=True)\n",
    "        \n",
    "        # Exit code\n",
    "        if errors:\n",
    "            raise click.Abort()\n",
    "        \n",
    "        if strict and warnings:\n",
    "            click.echo(\"Failing due to --strict mode\")\n",
    "            raise click.Abort()\n",
    "    \n",
    "    except yaml.YAMLError as e:\n",
    "        click.secho(f\"‚ùå YAML parse error: {e}\", fg='red', err=True)\n",
    "        raise click.Abort()\n",
    "    \n",
    "    except click.Abort:\n",
    "        raise\n",
    "    \n",
    "    except Exception as e:\n",
    "        click.secho(f\"‚ùå Unexpected error: {e}\", fg='red', err=True)\n",
    "        if verbose:\n",
    "            import traceback\n",
    "            click.echo(traceback.format_exc())\n",
    "        raise click.Abort()\n",
    "\n",
    "# Test\n",
    "runner = CliRunner()\n",
    "\n",
    "with runner.isolated_filesystem():\n",
    "    # Create test config\n",
    "    config_content = \"\"\"\n",
    "connections:\n",
    "  db:\n",
    "    type: databricks\n",
    "    catalog: main\n",
    "\n",
    "pipelines:\n",
    "  sales_etl:\n",
    "    steps:\n",
    "      - extract:\n",
    "          sql: \"SELECT * FROM sales\"\n",
    "          explanation: |\n",
    "            **Purpose:** Extract raw sales data\n",
    "            **Details:** Pulls all columns from sales table\n",
    "            **Result:** Returns complete sales dataset\n",
    "\"\"\"\n",
    "    \n",
    "    with open('config.yaml', 'w') as f:\n",
    "        f.write(config_content)\n",
    "    \n",
    "    result = runner.invoke(validate, ['config.yaml', '--verbose'])\n",
    "    print(result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Click Architecture**\n",
    "   - Decorator-based commands\n",
    "   - Command groups for multi-command CLIs\n",
    "   - Automatic help and validation\n",
    "\n",
    "2. **Rich Error Messages**\n",
    "   - Custom exception hierarchy\n",
    "   - Context-aware error formatting\n",
    "   - Actionable suggestions\n",
    "\n",
    "3. **Validation Workflow**\n",
    "   - Multi-stage validation\n",
    "   - Explanation quality linting\n",
    "   - Progress indication\n",
    "\n",
    "4. **Testing**\n",
    "   - CliRunner for isolated tests\n",
    "   - Temporary filesystem\n",
    "   - Exit code verification\n",
    "\n",
    "### Click vs argparse\n",
    "\n",
    "| Feature | argparse | Click |\n",
    "|---------|----------|-------|\n",
    "| Syntax | Verbose | Concise |\n",
    "| Testing | Manual | Built-in runner |\n",
    "| Validation | Manual | Automatic |\n",
    "| Composability | Limited | Excellent |\n",
    "| File handling | Manual | Built-in types |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Complete exercises to practice:\n",
    "- Building multi-command CLIs\n",
    "- Adding progress bars\n",
    "- Creating config linters\n",
    "- Implementing dry-run mode\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
