{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Odibi Configuration System\n",
    "\n",
    "Practice extending and working with Odibi's config architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Add New Enum - PartitionStrategy\n",
    "\n",
    "**Goal**: Create a new enum for partition strategies used in data writing.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create `PartitionStrategy` enum with values:\n",
    "   - `NONE` = \"none\"\n",
    "   - `HASH` = \"hash\"\n",
    "   - `RANGE` = \"range\"\n",
    "   - `DATE` = \"date\"\n",
    "2. Inherit from `str, Enum`\n",
    "3. Add docstring\n",
    "4. Test with Pydantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "# TODO: Create PartitionStrategy enum\n",
    "\n",
    "# TODO: Create test model\n",
    "# class PartitionConfig(BaseModel):\n",
    "#     strategy: PartitionStrategy\n",
    "#     columns: List[str] = Field(default_factory=list)\n",
    "\n",
    "# TODO: Test valid and invalid values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Add Partitioning to WriteConfig\n",
    "\n",
    "**Goal**: Extend `WriteConfig` to support partitioning.\n",
    "\n",
    "**Requirements**:\n",
    "1. Add optional `partition_strategy` field (use your enum from Exercise 1)\n",
    "2. Add optional `partition_columns` field (list of strings)\n",
    "3. Add model validator: if `partition_strategy` is not `NONE`, `partition_columns` must be provided\n",
    "4. Test all scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Dict, Any\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "\n",
    "# Copy your PartitionStrategy from Exercise 1\n",
    "\n",
    "class WriteMode(str, Enum):\n",
    "    OVERWRITE = \"overwrite\"\n",
    "    APPEND = \"append\"\n",
    "\n",
    "# TODO: Create enhanced WriteConfig\n",
    "# class WriteConfig(BaseModel):\n",
    "#     connection: str\n",
    "#     format: str\n",
    "#     table: Optional[str] = None\n",
    "#     path: Optional[str] = None\n",
    "#     mode: WriteMode = WriteMode.OVERWRITE\n",
    "#     options: Dict[str, Any] = Field(default_factory=dict)\n",
    "#     \n",
    "#     # TODO: Add partition fields\n",
    "#     # TODO: Add validators\n",
    "\n",
    "# TODO: Test cases\n",
    "# 1. No partitioning (valid)\n",
    "# 2. Partitioning with columns (valid)\n",
    "# 3. Partitioning without columns (invalid - should error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Create ScheduleConfig\n",
    "\n",
    "**Goal**: Add scheduling configuration for pipelines.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create `ScheduleType` enum:\n",
    "   - `MANUAL` = \"manual\"\n",
    "   - `CRON` = \"cron\"\n",
    "   - `INTERVAL` = \"interval\"\n",
    "2. Create `ScheduleConfig` model:\n",
    "   - `type: ScheduleType`\n",
    "   - `cron_expression: Optional[str]` (required if type is CRON)\n",
    "   - `interval_minutes: Optional[int]` (required if type is INTERVAL)\n",
    "3. Add model validator to enforce the requirements above\n",
    "4. Test all three schedule types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement ScheduleType enum\n",
    "\n",
    "# TODO: Implement ScheduleConfig with validation\n",
    "\n",
    "# TODO: Test cases:\n",
    "# 1. Manual schedule (no extra fields needed)\n",
    "# 2. Cron schedule with expression\n",
    "# 3. Interval schedule with minutes\n",
    "# 4. Cron without expression (should fail)\n",
    "# 5. Interval without minutes (should fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Discriminated Union - Storage Configs\n",
    "\n",
    "**Goal**: Create different storage configurations based on storage type.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create `StorageType` enum: `S3`, `GCS`, `AZURE`, `LOCAL`\n",
    "2. Create base `BaseStorageConfig` with:\n",
    "   - `type: StorageType`\n",
    "   - `encryption: bool = False`\n",
    "3. Create specific configs:\n",
    "   - `S3StorageConfig`: bucket, region, access_key_id (optional)\n",
    "   - `GCSStorageConfig`: bucket, project\n",
    "   - `AzureStorageConfig`: account_name, container, sas_token (optional)\n",
    "   - `LocalStorageConfig`: base_path\n",
    "4. Create union type `StorageConfig`\n",
    "5. Test each storage type validates correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "# TODO: Implement storage config hierarchy\n",
    "\n",
    "# TODO: Test each storage type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Field Validator - Validate Cron Expression\n",
    "\n",
    "**Goal**: Add field-level validation for cron expressions.\n",
    "\n",
    "**Requirements**:\n",
    "1. Extend `ScheduleConfig` from Exercise 3\n",
    "2. Add `@field_validator` for `cron_expression`\n",
    "3. Validate it has exactly 5 parts (minute, hour, day, month, weekday)\n",
    "4. Each part should be either `*`, a number, or a range\n",
    "5. Provide clear error messages\n",
    "\n",
    "**Example valid expressions**:\n",
    "- `\"0 0 * * *\"` (daily at midnight)\n",
    "- `\"*/15 * * * *\"` (every 15 minutes)\n",
    "- `\"0 9-17 * * 1-5\"` (hourly, 9am-5pm, weekdays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import field_validator\n",
    "import re\n",
    "\n",
    "# TODO: Enhance ScheduleConfig with field validator\n",
    "# class ScheduleConfig(BaseModel):\n",
    "#     type: ScheduleType\n",
    "#     cron_expression: Optional[str] = None\n",
    "#     interval_minutes: Optional[int] = None\n",
    "#     \n",
    "#     @field_validator(\"cron_expression\")\n",
    "#     @classmethod\n",
    "#     def validate_cron(cls, v):\n",
    "#         # TODO: Implement validation\n",
    "#         pass\n",
    "\n",
    "# TODO: Test valid and invalid cron expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Complete Pipeline Config with Extensions\n",
    "\n",
    "**Goal**: Create a complete pipeline config using all your new features.\n",
    "\n",
    "**Requirements**:\n",
    "1. Add `schedule` field to `PipelineConfig` (use your `ScheduleConfig`)\n",
    "2. Create YAML for a pipeline with:\n",
    "   - Schedule (cron-based)\n",
    "   - Multiple nodes\n",
    "   - At least one write operation with partitioning\n",
    "3. Load and validate it\n",
    "4. Print summary of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# TODO: Define enhanced PipelineConfig\n",
    "\n",
    "# TODO: Create YAML configuration\n",
    "pipeline_yaml = \"\"\"\n",
    "# Your YAML here\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Load and validate\n",
    "\n",
    "# TODO: Print summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Error Message Quality\n",
    "\n",
    "**Goal**: Practice writing helpful validation errors.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create a config model with complex validation\n",
    "2. Each validation error should:\n",
    "   - Clearly state what's wrong\n",
    "   - Suggest what to do instead\n",
    "   - Include relevant context (e.g., available options)\n",
    "3. Test multiple error scenarios\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "raise ValueError(\n",
    "    f\"Connection '{conn_name}' not found. \"\n",
    "    f\"Available connections: {', '.join(available)}. \"\n",
    "    f\"Add it to the 'connections' section of your YAML.\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create config model with helpful error messages\n",
    "\n",
    "# TODO: Test and show error messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Config Inheritance\n",
    "\n",
    "**Goal**: Implement config inheritance/overrides.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create a `merge_configs` function that:\n",
    "   - Takes a base config and override config\n",
    "   - Returns merged config (override takes precedence)\n",
    "   - Handles nested dictionaries\n",
    "2. Use it to implement environment-specific overrides\n",
    "3. Test with dev/prod configs\n",
    "\n",
    "**Example**:\n",
    "```python\n",
    "base = {\"logging\": {\"level\": \"INFO\", \"structured\": False}}\n",
    "prod = {\"logging\": {\"level\": \"ERROR\"}}\n",
    "merged = merge_configs(base, prod)\n",
    "# Result: {\"logging\": {\"level\": \"ERROR\", \"structured\": False}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_configs(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Merge two config dictionaries, override takes precedence.\"\"\"\n",
    "    # TODO: Implement\n",
    "    pass\n",
    "\n",
    "# TODO: Test with various scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9: Config Testing Framework\n",
    "\n",
    "**Goal**: Write comprehensive tests for your configs.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create test functions for:\n",
    "   - Valid configs (should succeed)\n",
    "   - Invalid configs (should fail with specific errors)\n",
    "   - Edge cases (empty lists, missing optionals, etc.)\n",
    "2. Use pytest-style assertions\n",
    "3. Test at least 3 different config models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write test functions\n",
    "\n",
    "def test_write_config_valid():\n",
    "    \"\"\"Test valid WriteConfig.\"\"\"\n",
    "    # TODO: Implement\n",
    "    pass\n",
    "\n",
    "def test_write_config_missing_table_and_path():\n",
    "    \"\"\"Test WriteConfig with neither table nor path fails.\"\"\"\n",
    "    # TODO: Implement\n",
    "    pass\n",
    "\n",
    "# TODO: Add more tests\n",
    "\n",
    "# Run tests\n",
    "# test_write_config_valid()\n",
    "# test_write_config_missing_table_and_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Exercise: Complete Feature - Data Quality Config\n",
    "\n",
    "**Goal**: Design and implement a complete data quality configuration system.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create enums for:\n",
    "   - `QualityCheckType`: `SCHEMA`, `COMPLETENESS`, `UNIQUENESS`, `RANGE`, `CUSTOM`\n",
    "   - `Severity`: `WARNING`, `ERROR`, `CRITICAL`\n",
    "2. Create config models:\n",
    "   - `SchemaCheck`: Expected column names and types\n",
    "   - `CompletenessCheck`: Columns that can't be null, min fill rate\n",
    "   - `UniquenessCheck`: Columns that must be unique\n",
    "   - `RangeCheck`: Min/max values for numeric columns\n",
    "   - `CustomCheck`: SQL expression or Python function\n",
    "3. Create `QualityConfig` that includes list of checks\n",
    "4. Add to `NodeConfig` as optional field\n",
    "5. Create comprehensive YAML example\n",
    "6. Write tests for all check types\n",
    "\n",
    "This is a realistic production feature - take your time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement complete data quality config system\n",
    "\n",
    "# Your implementation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Learning Checklist\n",
    "\n",
    "After completing these exercises, you should be able to:\n",
    "\n",
    "- [ ] Create and use custom enums with Pydantic\n",
    "- [ ] Write field validators with constraints and patterns\n",
    "- [ ] Write model validators for cross-field validation\n",
    "- [ ] Create discriminated unions for polymorphic configs\n",
    "- [ ] Design clear, helpful error messages\n",
    "- [ ] Test configuration models thoroughly\n",
    "- [ ] Work with nested Pydantic models\n",
    "- [ ] Load and validate YAML configurations\n",
    "- [ ] Extend existing config systems with new features\n",
    "\n",
    "**Solutions**: See `solutions.ipynb` for reference implementations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
